{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project: Train a Quadcopter How to Fly\n",
    "\n",
    "Design an agent to fly a quadcopter, and then train it using a reinforcement learning algorithm of your choice! \n",
    "\n",
    "Try to apply the techniques you have learnt, but also feel free to come up with innovative ideas and test them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install tflearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 1 [ 2.] [-2.]\n",
      "Episode =    1total_reward -1002.35642565\n",
      "Episode =    2total_reward -1676.53515273\n",
      "Episode =    3total_reward -1293.68792629\n",
      "Episode =    4total_reward -1508.07416154\n",
      "Episode =    5total_reward -1293.15228303\n",
      "Episode =    6total_reward -1131.95569578\n",
      "Episode =    7total_reward -1655.72831107\n",
      "Episode =    8total_reward -1714.89180101\n",
      "Episode =    9total_reward -1525.94108247\n",
      "Episode =   10total_reward -1490.04829722\n",
      "Episode =   11total_reward -1396.48413043\n",
      "Episode =   12total_reward -1486.10518655\n",
      "Episode =   13total_reward -1506.89556731\n",
      "Episode =   14total_reward -1493.12985094\n",
      "Episode =   15total_reward -1473.54443791\n",
      "Episode =   16total_reward -1514.05777757\n",
      "Episode =   17total_reward -1512.4287791\n",
      "Episode =   18total_reward -1171.66039719\n",
      "Episode =   19total_reward -1557.2715324\n",
      "Episode =   20total_reward -1479.27292406\n",
      "Episode =   21total_reward -1429.75270209\n",
      "Episode =   22total_reward -1313.38441704\n",
      "Episode =   23total_reward -1492.24515676\n",
      "Episode =   24total_reward -1444.30205595\n",
      "Episode =   25total_reward -905.016082616\n",
      "Episode =   26total_reward -1122.80414593\n",
      "Episode =   27total_reward -1416.75953128\n",
      "Episode =   28total_reward -1539.7773984\n",
      "Episode =   29total_reward -1503.1994692\n",
      "Episode =   30total_reward -1596.77249304\n",
      "Episode =   31total_reward -1462.6413358\n",
      "Episode =   32total_reward -1525.93162238\n",
      "Episode =   33total_reward -1278.22638034\n",
      "Episode =   34total_reward -1431.02111105\n",
      "Episode =   35total_reward -1182.49541257\n",
      "Episode =   36total_reward -1447.04699995\n",
      "Episode =   37total_reward -1225.17002179\n",
      "Episode =   38total_reward -1434.74423006\n",
      "Episode =   39total_reward -1394.4559348\n",
      "Episode =   40total_reward -1516.93835315\n",
      "Episode =   41total_reward -1172.6081283\n",
      "Episode =   42total_reward -1563.18930517\n",
      "Episode =   43total_reward -1056.52258232\n",
      "Episode =   44total_reward -1210.50753386\n",
      "Episode =   45total_reward -896.197427688\n",
      "Episode =   46total_reward -1110.84142769\n",
      "Episode =   47total_reward -1483.90897245\n",
      "Episode =   48total_reward -1349.19079173\n",
      "Episode =   49total_reward -1469.41006154\n",
      "Episode =   50total_reward -886.917443347\n",
      "Episode =   51total_reward -1497.87077716\n",
      "Episode =   52total_reward -1537.76497271\n",
      "Episode =   53total_reward -1523.14543626\n",
      "Episode =   54total_reward -1053.90564375\n",
      "Episode =   55total_reward -1556.54368704\n",
      "Episode =   56total_reward -1395.38014281\n",
      "Episode =   57total_reward -1476.84878639\n",
      "Episode =   58total_reward -1170.05533479\n",
      "Episode =   59total_reward -1525.3941262\n",
      "Episode =   60total_reward -1309.19475025\n",
      "Episode =   61total_reward -1141.70656705\n",
      "Episode =   62total_reward -1484.31561312\n",
      "Episode =   63total_reward -1370.20268503\n",
      "Episode =   64total_reward -991.526405279\n",
      "Episode =   65total_reward -1067.42515577\n",
      "Episode =   66total_reward -278.43059219\n",
      "Episode =   67total_reward -1279.12405051\n",
      "Episode =   68total_reward -1142.27176862\n",
      "Episode =   69total_reward -925.04579184\n",
      "Episode =   70total_reward -1099.41109399\n",
      "Episode =   71total_reward -1515.04041373\n",
      "Episode =   72total_reward -787.577321801\n",
      "Episode =   73total_reward -539.428478775\n",
      "Episode =   74total_reward -975.494845222\n",
      "Episode =   75total_reward -783.826353955\n",
      "Episode =   76total_reward -1181.09483156\n",
      "Episode =   77total_reward -544.776439838\n",
      "Episode =   78total_reward -257.8303576\n",
      "Episode =   79total_reward -824.778155993\n",
      "Episode =   80total_reward -572.942547707\n",
      "Episode =   81total_reward -1231.09243021\n",
      "Episode =   82total_reward -652.75075863\n",
      "Episode =   83total_reward -275.918461164\n",
      "Episode =   84total_reward -1503.1123561\n",
      "Episode =   85total_reward -812.800601151\n",
      "Episode =   86total_reward -541.374441158\n",
      "Episode =   87total_reward -1385.38969131\n",
      "Episode =   88total_reward -773.422459235\n",
      "Episode =   89total_reward -1028.74386477\n",
      "Episode =   90total_reward -520.865062291\n",
      "Episode =   91total_reward -512.789753797\n",
      "Episode =   92total_reward -741.751241521\n",
      "Episode =   93total_reward -264.68789932\n",
      "Episode =   94total_reward -776.441350652\n",
      "Episode =   95total_reward -15.0602735856\n",
      "Episode =   96total_reward -523.366682753\n",
      "Episode =   97total_reward -532.388291741\n",
      "Episode =   98total_reward -564.413999096\n",
      "Episode =   99total_reward -530.18693603\n",
      "Episode =  100total_reward -773.841783311\n",
      "Episode =  101total_reward -1076.35327982\n",
      "Episode =  102total_reward -520.916719532\n",
      "Episode =  103total_reward -777.695811627\n",
      "Episode =  104total_reward -541.015336894\n",
      "Episode =  105total_reward -771.729004755\n",
      "Episode =  106total_reward -519.122111261\n",
      "Episode =  107total_reward -979.203667614\n",
      "Episode =  108total_reward -538.012694253\n",
      "Episode =  109total_reward -518.89423991\n",
      "Episode =  110total_reward -550.300423437\n",
      "Episode =  111total_reward -1078.9962946\n",
      "Episode =  112total_reward -1505.95263833\n",
      "Episode =  113total_reward -1239.47574599\n",
      "Episode =  114total_reward -880.623826089\n",
      "Episode =  115total_reward -519.092991295\n",
      "Episode =  116total_reward -828.709881491\n",
      "Episode =  117total_reward -516.914612882\n",
      "Episode =  118total_reward -265.875788465\n",
      "Episode =  119total_reward -780.259783497\n",
      "Episode =  120total_reward -1532.28238047\n",
      "Episode =  121total_reward -825.395944445\n",
      "Episode =  122total_reward -266.161563016\n",
      "Episode =  123total_reward -1536.00537984\n",
      "Episode =  124total_reward -366.061307651\n",
      "Episode =  125total_reward -786.553963792\n",
      "Episode =  126total_reward -802.404094249\n",
      "Episode =  127total_reward -270.888020568\n",
      "Episode =  128total_reward -513.172511816\n",
      "Episode =  129total_reward -263.005203982\n",
      "Episode =  130total_reward -1080.90747133\n",
      "Episode =  131total_reward -268.444199957\n",
      "Episode =  132total_reward -341.253055075\n",
      "Episode =  133total_reward -806.540773145\n",
      "Episode =  134total_reward -1541.11583228\n",
      "Episode =  135total_reward -765.979230933\n",
      "Episode =  136total_reward -254.392604437\n",
      "Episode =  137total_reward -516.319519027\n",
      "Episode =  138total_reward -8.55230897671\n",
      "Episode =  139total_reward -567.774854096\n",
      "Episode =  140total_reward -584.681730936\n",
      "Episode =  141total_reward -517.951230895\n",
      "Episode =  142total_reward -813.863626344\n",
      "Episode =  143total_reward -535.470219353\n",
      "Episode =  144total_reward -1389.89871589\n",
      "Episode =  145total_reward -1565.30494811\n",
      "Episode =  146total_reward -260.379373855\n",
      "Episode =  147total_reward -503.673057908\n",
      "Episode =  148total_reward -535.136518333\n",
      "Episode =  149total_reward -957.177321058\n",
      "Episode =  150total_reward -262.938734288\n",
      "Episode =  151total_reward -764.111755213\n",
      "Episode =  152total_reward -255.19956042\n",
      "Episode =  153total_reward -1036.19569245\n",
      "Episode =  154total_reward -266.671799444\n",
      "Episode =  155total_reward -1.38378635381\n",
      "Episode =  156total_reward -518.668641963\n",
      "Episode =  157total_reward -542.634327534\n",
      "Episode =  158total_reward -512.725762426\n",
      "Episode =  159total_reward -1415.73852612\n",
      "Episode =  160total_reward -1498.46615003\n",
      "Episode =  161total_reward -800.526099046\n",
      "Episode =  162total_reward -259.493323784\n",
      "Episode =  163total_reward -551.857348713\n",
      "Episode =  164total_reward -257.376495017\n",
      "Episode =  165total_reward -257.339669244\n",
      "Episode =  166total_reward -514.227643489\n",
      "Episode =  167total_reward -1320.00079741\n",
      "Episode =  168total_reward -565.924189651\n",
      "Episode =  169total_reward -430.230583631\n",
      "Episode =  170total_reward -253.884270257\n",
      "Episode =  171total_reward -521.005398839\n",
      "Episode =  172total_reward -257.017384757\n",
      "Episode =  173total_reward -502.605261838\n",
      "Episode =  174total_reward -4.09791736884\n",
      "Episode =  175total_reward -1.30862187575\n",
      "Episode =  176total_reward -607.469297207\n",
      "Episode =  177total_reward -703.049262456\n",
      "Episode =  178total_reward -774.701051566\n",
      "Episode =  179total_reward -4.71726300366\n",
      "Episode =  180total_reward -736.740998282\n",
      "Episode =  181total_reward -256.988761717\n",
      "Episode =  182total_reward -255.226308387\n",
      "Episode =  183total_reward -244.590953395\n",
      "Episode =  184total_reward -760.92543822\n",
      "Episode =  185total_reward -887.924382417\n",
      "Episode =  186total_reward -506.392568321\n",
      "Episode =  187total_reward -510.323928097\n",
      "Episode =  188total_reward -528.552177993\n",
      "Episode =  189total_reward -1361.02017153\n",
      "Episode =  190total_reward -1531.46097539\n",
      "Episode =  191total_reward -1336.67925434\n",
      "Episode =  192total_reward -523.700810789\n",
      "Episode =  193total_reward -541.997968739\n",
      "Episode =  194total_reward -264.557585935\n",
      "Episode =  195total_reward -257.234278275\n",
      "Episode =  196total_reward -492.352770402\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode =  197total_reward -260.694398552\n",
      "Episode =  198total_reward -517.286457836\n",
      "Episode =  199total_reward -473.369055469\n",
      "Episode =  200total_reward -511.94423317\n",
      "Episode =  201total_reward -258.573078515\n",
      "Episode =  202total_reward -248.09363499\n",
      "Episode =  203total_reward -258.070880575\n",
      "Episode =  204total_reward -772.937663836\n",
      "Episode =  205total_reward -519.764337903\n",
      "Episode =  206total_reward -516.227496343\n",
      "Episode =  207total_reward -509.190795118\n",
      "Episode =  208total_reward -731.991058644\n",
      "Episode =  209total_reward -246.344258351\n",
      "Episode =  210total_reward -257.497740234\n",
      "Episode =  211total_reward -258.25867785\n",
      "Episode =  212total_reward -981.850891242\n",
      "Episode =  213total_reward -779.870751476\n",
      "Episode =  214total_reward -262.812164787\n",
      "Episode =  215total_reward -753.327977561\n",
      "Episode =  216total_reward -520.709502421\n",
      "Episode =  217total_reward -505.07434935\n",
      "Episode =  218total_reward -252.28908276\n",
      "Episode =  219total_reward -153.771973594\n",
      "Episode =  220total_reward -349.202518794\n",
      "Episode =  221total_reward -240.626638541\n",
      "Episode =  222total_reward -242.139258328\n",
      "Episode =  223total_reward -774.324377429\n",
      "Episode =  224total_reward -259.524664687\n",
      "Episode =  225total_reward -251.342351158\n",
      "Episode =  226total_reward -669.682254803\n",
      "Episode =  227total_reward -516.161276749\n",
      "Episode =  228total_reward -250.46819683\n",
      "Episode =  229total_reward -251.547671105\n",
      "Episode =  230total_reward -261.403478514\n",
      "Episode =  231total_reward -77.238852792\n",
      "Episode =  232total_reward -252.102325054\n",
      "Episode =  233total_reward -555.245805587\n",
      "Episode =  234total_reward -471.172263989\n",
      "Episode =  235total_reward -489.197783778\n",
      "Episode =  236total_reward -291.221634856\n",
      "Episode =  237total_reward -255.716553756\n",
      "Episode =  238total_reward -491.454610016\n",
      "Episode =  239total_reward -248.820096869\n",
      "Episode =  240total_reward -253.311648193\n",
      "Episode =  241total_reward -240.745510229\n",
      "Episode =  242total_reward -475.756779773\n",
      "Episode =  243total_reward -476.535041402\n",
      "Episode =  244total_reward -247.138932076\n",
      "Episode =  245total_reward -251.013639324\n",
      "Episode =  246total_reward -259.126569961\n",
      "Episode =  247total_reward -252.876410401\n",
      "Episode =  248total_reward -520.002976495\n",
      "Episode =  249total_reward -494.767968446\n",
      "Episode =  250total_reward -254.597248782\n",
      "Episode =  251total_reward -508.823409836\n",
      "Episode =  252total_reward -255.826853692\n",
      "Episode =  253total_reward -245.073064842\n",
      "Episode =  254total_reward -1001.14992675\n",
      "Episode =  255total_reward -253.283731162\n",
      "Episode =  256total_reward -1.31565356683\n",
      "Episode =  257total_reward -243.555937364\n",
      "Episode =  258total_reward -478.290823901\n",
      "Episode =  259total_reward -0.521213186948\n",
      "Episode =  260total_reward -247.054478879\n",
      "Episode =  261total_reward -3.56139873676\n",
      "Episode =  262total_reward -256.1847231\n",
      "Episode =  263total_reward -251.402428476\n",
      "Episode =  264total_reward -237.042893774\n",
      "Episode =  265total_reward -250.074974926\n",
      "Episode =  266total_reward -497.913893184\n",
      "Episode =  267total_reward -237.398650061\n",
      "Episode =  268total_reward -251.211041482\n",
      "Episode =  269total_reward -244.056032573\n",
      "Episode =  270total_reward -247.511543586\n",
      "Episode =  271total_reward -706.099003548\n",
      "Episode =  272total_reward -244.066011836\n",
      "Episode =  273total_reward -252.941295073\n",
      "Episode =  274total_reward -710.364568853\n",
      "Episode =  275total_reward -257.755452671\n",
      "Episode =  276total_reward -251.722516646\n",
      "Episode =  277total_reward -787.963825232\n",
      "Episode =  278total_reward -245.923438433\n",
      "Episode =  279total_reward -10.4752847092\n",
      "Episode =  280total_reward -250.145954831\n",
      "Episode =  281total_reward -255.681663076\n",
      "Episode =  282total_reward -245.277436308\n",
      "Episode =  283total_reward -475.899468613\n",
      "Episode =  284total_reward -1.12271754339\n",
      "Episode =  285total_reward -246.90202707\n",
      "Episode =  286total_reward -255.800205597\n",
      "Episode =  287total_reward -483.542556881\n",
      "Episode =  288total_reward -496.495975883\n",
      "Episode =  289total_reward -246.17295411\n",
      "Episode =  290total_reward -620.441952598\n",
      "Episode =  291total_reward -498.532534833\n",
      "Episode =  292total_reward -244.024217673\n",
      "Episode =  293total_reward -256.337051586\n",
      "Episode =  294total_reward -255.441052634\n",
      "Episode =  295total_reward -476.18715029\n",
      "Episode =  296total_reward -3.73841826934\n",
      "Episode =  297total_reward -250.606840533\n",
      "Episode =  298total_reward -251.437270574\n",
      "Episode =  299total_reward -243.690113324\n",
      "Episode =  300total_reward -820.741298228\n",
      "Episode =  301total_reward -488.414184249\n",
      "Episode =  302total_reward -741.592173332\n",
      "Episode =  303total_reward -255.731492856\n",
      "Episode =  304total_reward -252.106768661\n",
      "Episode =  305total_reward -5.25918546042\n",
      "Episode =  306total_reward -476.401410168\n",
      "Episode =  307total_reward -509.008116209\n",
      "Episode =  308total_reward -750.852501473\n",
      "Episode =  309total_reward -250.32190225\n",
      "Episode =  310total_reward -249.733542826\n",
      "Episode =  311total_reward -247.098595323\n",
      "Episode =  312total_reward -493.825349676\n",
      "Episode =  313total_reward -254.60083412\n",
      "Episode =  314total_reward -239.855643195\n",
      "Episode =  315total_reward -247.260364285\n",
      "Episode =  316total_reward -699.221288524\n",
      "Episode =  317total_reward -489.833889849\n",
      "Episode =  318total_reward -469.266481818\n",
      "Episode =  319total_reward -486.961643734\n",
      "Episode =  320total_reward -509.380644751\n",
      "Episode =  321total_reward -718.775291425\n",
      "Episode =  322total_reward -257.614762894\n",
      "Episode =  323total_reward -6.91347207748\n",
      "Episode =  324total_reward -257.430137018\n",
      "Episode =  325total_reward -13.7636478932\n",
      "Episode =  326total_reward -492.098041604\n",
      "Episode =  327total_reward -440.105084091\n",
      "Episode =  328total_reward -9.89541308075\n",
      "Episode =  329total_reward -250.508732174\n",
      "Episode =  330total_reward -236.80116164\n",
      "Episode =  331total_reward -754.952946072\n",
      "Episode =  332total_reward -724.408126747\n",
      "Episode =  333total_reward -251.375276509\n",
      "Episode =  334total_reward -846.930105633\n",
      "Episode =  335total_reward -253.637865683\n",
      "Episode =  336total_reward -256.524212604\n",
      "Episode =  337total_reward -247.410176665\n",
      "Episode =  338total_reward -240.498666253\n",
      "Episode =  339total_reward -297.20135659\n",
      "Episode =  340total_reward -485.513533071\n",
      "Episode =  341total_reward -475.073535498\n",
      "Episode =  342total_reward -368.278980845\n",
      "Episode =  343total_reward -472.298994073\n",
      "Episode =  344total_reward -249.420397706\n",
      "Episode =  345total_reward -1197.48333756\n",
      "Episode =  346total_reward -486.444913344\n",
      "Episode =  347total_reward -301.371263559\n",
      "Episode =  348total_reward -499.43771154\n",
      "Episode =  349total_reward -506.387317696\n",
      "Episode =  350total_reward -500.810050529\n",
      "Episode =  351total_reward -508.381051546\n",
      "Episode =  352total_reward -520.747989591\n",
      "Episode =  353total_reward -256.651120344\n",
      "Episode =  354total_reward -1552.0634141\n",
      "Episode =  355total_reward -263.356054261\n",
      "Episode =  356total_reward -258.954140782\n",
      "Episode =  357total_reward -256.687901228\n",
      "Episode =  358total_reward -796.418792923\n",
      "Episode =  359total_reward -472.123724152\n",
      "Episode =  360total_reward -235.582056457\n",
      "Episode =  361total_reward -497.475724466\n",
      "Episode =  362total_reward -255.189689503\n",
      "Episode =  363total_reward -242.8335787\n",
      "Episode =  364total_reward -1134.7758271\n",
      "Episode =  365total_reward -260.297678399\n",
      "Episode =  366total_reward -399.688829509\n",
      "Episode =  367total_reward -579.402477518\n",
      "Episode =  368total_reward -245.778664973\n",
      "Episode =  369total_reward -260.668230056\n",
      "Episode =  370total_reward -259.494514726\n",
      "Episode =  371total_reward -360.207330136\n",
      "Episode =  372total_reward -256.383216046\n",
      "Episode =  373total_reward -12.8528775486\n",
      "Episode =  374total_reward -501.573850966\n",
      "Episode =  375total_reward -773.308273921\n",
      "Episode =  376total_reward -254.648333944\n",
      "Episode =  377total_reward -507.782886883\n",
      "Episode =  378total_reward -690.066669626\n",
      "Episode =  379total_reward -513.871487782\n",
      "Episode =  380total_reward -750.909771548\n",
      "Episode =  381total_reward -546.459602392\n",
      "Episode =  382total_reward -516.743754672\n",
      "Episode =  383total_reward -494.520573161\n",
      "Episode =  384total_reward -579.36514794\n",
      "Episode =  385total_reward -262.11972161\n",
      "Episode =  386total_reward -255.291129792\n",
      "Episode =  387total_reward -248.624059529\n",
      "Episode =  388total_reward -959.283869925\n",
      "Episode =  389total_reward -7.2833170705\n",
      "Episode =  390total_reward -774.72416371\n",
      "Episode =  391total_reward -507.445275127\n",
      "Episode =  392total_reward -259.942135\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode =  393total_reward -504.497478006\n",
      "Episode =  394total_reward -256.018770492\n",
      "Episode =  395total_reward -924.398874707\n",
      "Episode =  396total_reward -258.398097706\n",
      "Episode =  397total_reward -252.204378923\n",
      "Episode =  398total_reward -201.506130578\n",
      "Episode =  399total_reward -243.835325159\n",
      "Episode =  400total_reward -1450.45788386\n",
      "Episode =  401total_reward -256.848372975\n",
      "Episode =  402total_reward -231.756522374\n",
      "Episode =  403total_reward -264.050780083\n",
      "Episode =  404total_reward -430.371231857\n",
      "Episode =  405total_reward -265.366128631\n",
      "Episode =  406total_reward -488.685724021\n",
      "Episode =  407total_reward -490.657524028\n",
      "Episode =  408total_reward -251.332741196\n",
      "Episode =  409total_reward -506.37277735\n",
      "Episode =  410total_reward -252.286069491\n",
      "Episode =  411total_reward -261.494130556\n",
      "Episode =  412total_reward -265.611644107\n",
      "Episode =  413total_reward -740.997447432\n",
      "Episode =  414total_reward -253.984369312\n",
      "Episode =  415total_reward -478.808573843\n",
      "Episode =  416total_reward -492.686778669\n",
      "Episode =  417total_reward -739.221910457\n",
      "Episode =  418total_reward -250.418240344\n",
      "Episode =  419total_reward -505.602727587\n",
      "Episode =  420total_reward -717.168885667\n",
      "Episode =  421total_reward -254.813286764\n",
      "Episode =  422total_reward -238.525768598\n",
      "Episode =  423total_reward -238.135933047\n",
      "Episode =  424total_reward -264.106702408\n",
      "Episode =  425total_reward -634.336082969\n",
      "Episode =  426total_reward -262.44311694\n",
      "Episode =  427total_reward -787.790083986\n",
      "Episode =  428total_reward -248.653126761\n",
      "Episode =  429total_reward -250.155803954\n",
      "Episode =  430total_reward -489.232062067\n",
      "Episode =  431total_reward -740.638504821\n",
      "Episode =  432total_reward -488.612555504\n",
      "Episode =  433total_reward -523.304423207\n",
      "Episode =  434total_reward -10.3614856314\n",
      "Episode =  435total_reward -252.296117159\n",
      "Episode =  436total_reward -498.622938983\n",
      "Episode =  437total_reward -514.7060516\n",
      "Episode =  438total_reward -479.618445325\n",
      "Episode =  439total_reward -258.195347486\n",
      "Episode =  440total_reward -436.842609292\n",
      "Episode =  441total_reward -259.598963557\n",
      "Episode =  442total_reward -262.474162398\n",
      "Episode =  443total_reward -496.95243066\n",
      "Episode =  444total_reward -503.607582798\n",
      "Episode =  445total_reward -257.333960039\n",
      "Episode =  446total_reward -509.110093721\n",
      "Episode =  447total_reward -512.526219464\n",
      "Episode =  448total_reward -410.703710305\n",
      "Episode =  449total_reward -730.467793875\n",
      "Episode =  450total_reward -497.210512623\n",
      "Episode =  451total_reward -713.909139538\n",
      "Episode =  452total_reward -272.656323274\n",
      "Episode =  453total_reward -486.317391485\n",
      "Episode =  454total_reward -474.857246878\n",
      "Episode =  455total_reward -510.081073147\n",
      "Episode =  456total_reward -517.452002712\n",
      "Episode =  457total_reward -514.29765839\n",
      "Episode =  458total_reward -265.504464774\n",
      "Episode =  459total_reward -747.538607916\n",
      "Episode =  460total_reward -509.702711405\n",
      "Episode =  461total_reward -500.483193886\n",
      "Episode =  462total_reward -257.942094193\n",
      "Episode =  463total_reward -485.497214558\n",
      "Episode =  464total_reward -732.114173009\n",
      "Episode =  465total_reward -235.746302684\n",
      "Episode =  466total_reward -264.587725004\n",
      "Episode =  467total_reward -500.320586809\n",
      "Episode =  468total_reward -260.131808769\n",
      "Episode =  469total_reward -254.096171783\n",
      "Episode =  470total_reward -506.999820822\n",
      "Episode =  471total_reward -277.995361342\n",
      "Episode =  472total_reward -266.843750251\n",
      "Episode =  473total_reward -9.88496142506\n",
      "Episode =  474total_reward -772.02759443\n",
      "Episode =  475total_reward -490.456764977\n",
      "Episode =  476total_reward -265.300870911\n",
      "Episode =  477total_reward -767.088746322\n",
      "Episode =  478total_reward -483.712324491\n",
      "Episode =  479total_reward -501.944002848\n",
      "Episode =  480total_reward -511.826745633\n",
      "Episode =  481total_reward -499.601304843\n",
      "Episode =  482total_reward -338.136578962\n",
      "Episode =  483total_reward -480.71361844\n",
      "Episode =  484total_reward -244.535807381\n",
      "Episode =  485total_reward -534.662761492\n",
      "Episode =  486total_reward -498.420948135\n",
      "Episode =  487total_reward -752.329396507\n",
      "Episode =  488total_reward -239.622476381\n",
      "Episode =  489total_reward -236.492942018\n",
      "Episode =  490total_reward -13.0470080353\n",
      "Episode =  491total_reward -498.751931687\n",
      "Episode =  492total_reward -234.950067112\n",
      "Episode =  493total_reward -259.255236936\n",
      "Episode =  494total_reward -257.290232668\n",
      "Episode =  495total_reward -740.348543441\n",
      "Episode =  496total_reward -11.5691589918\n",
      "Episode =  497total_reward -740.191870864\n",
      "Episode =  498total_reward -242.645957985\n",
      "Episode =  499total_reward -262.997429251\n",
      "Episode =  500total_reward -506.05302784\n",
      "Episode =  501total_reward -61.2690954499\n",
      "Episode =  502total_reward -571.748424719\n",
      "Episode =  503total_reward -479.383228211\n",
      "Episode =  504total_reward -237.956636599\n",
      "Episode =  505total_reward -504.940751379\n",
      "Episode =  506total_reward -250.678315817\n",
      "Episode =  507total_reward -314.96985616\n",
      "Episode =  508total_reward -380.082575202\n",
      "Episode =  509total_reward -244.328754817\n",
      "Episode =  510total_reward -259.88594478\n",
      "Episode =  511total_reward -14.000446725\n",
      "Episode =  512total_reward -491.614901681\n",
      "Episode =  513total_reward -856.398635006\n",
      "Episode =  514total_reward -724.106846544\n",
      "Episode =  515total_reward -247.004429545\n",
      "Episode =  516total_reward -261.317927374\n",
      "Episode =  517total_reward -246.772399911\n",
      "Episode =  518total_reward -976.301037365\n",
      "Episode =  519total_reward -693.926779509\n",
      "Episode =  520total_reward -512.568064768\n",
      "Episode =  521total_reward -507.216727819\n",
      "Episode =  522total_reward -246.954404784\n",
      "Episode =  523total_reward -504.922138379\n",
      "Episode =  524total_reward -472.509854675\n",
      "Episode =  525total_reward -495.882828112\n",
      "Episode =  526total_reward -235.877539148\n",
      "Episode =  527total_reward -262.021510021\n",
      "Episode =  528total_reward -494.728794776\n",
      "Episode =  529total_reward -764.527597346\n",
      "Episode =  530total_reward -496.476880373\n",
      "Episode =  531total_reward -731.754307337\n",
      "Episode =  532total_reward -472.496674034\n",
      "Episode =  533total_reward -709.305097692\n",
      "Episode =  534total_reward -529.302345864\n",
      "Episode =  535total_reward -540.698329813\n",
      "Episode =  536total_reward -266.79798335\n",
      "Episode =  537total_reward -96.9829220665\n",
      "Episode =  538total_reward -258.415224152\n",
      "Episode =  539total_reward -480.22242746\n",
      "Episode =  540total_reward -488.381122045\n",
      "Episode =  541total_reward -150.43206928\n",
      "Episode =  542total_reward -266.259474826\n",
      "Episode =  543total_reward -507.302385439\n",
      "Episode =  544total_reward -705.850400097\n",
      "Episode =  545total_reward -1000.5477837\n",
      "Episode =  546total_reward -508.917895576\n",
      "Episode =  547total_reward -512.778646435\n",
      "Episode =  548total_reward -464.176845975\n",
      "Episode =  549total_reward -266.084472329\n",
      "Episode =  550total_reward -262.340071529\n",
      "Episode =  551total_reward -491.07494967\n",
      "Episode =  552total_reward -717.547664432\n",
      "Episode =  553total_reward -763.573134847\n",
      "Episode =  554total_reward -259.981250452\n",
      "Episode =  555total_reward -13.5314018422\n",
      "Episode =  556total_reward -266.200129085\n",
      "Episode =  557total_reward -248.589946503\n",
      "Episode =  558total_reward -509.567147175\n",
      "Episode =  559total_reward -726.955685478\n",
      "Episode =  560total_reward -719.185077321\n",
      "Episode =  561total_reward -282.927960079\n",
      "Episode =  562total_reward -514.127539195\n",
      "Episode =  563total_reward -712.655798248\n",
      "Episode =  564total_reward -506.712877623\n",
      "Episode =  565total_reward -13.0327663569\n",
      "Episode =  566total_reward -929.130869431\n",
      "Episode =  567total_reward -242.593639558\n",
      "Episode =  568total_reward -262.811789616\n",
      "Episode =  569total_reward -726.132188187\n",
      "Episode =  570total_reward -266.077563732\n",
      "Episode =  571total_reward -259.751670427\n",
      "Episode =  572total_reward -255.752327478\n",
      "Episode =  573total_reward -485.123365144\n",
      "Episode =  574total_reward -257.505667596\n",
      "Episode =  575total_reward -501.33682393\n",
      "Episode =  576total_reward -264.310445531\n",
      "Episode =  577total_reward -673.273205327\n",
      "Episode =  578total_reward -747.994307096\n",
      "Episode =  579total_reward -498.007429191\n",
      "Episode =  580total_reward -517.032197087\n",
      "Episode =  581total_reward -788.839703504\n",
      "Episode =  582total_reward -255.519980368\n",
      "Episode =  583total_reward -175.086408032\n",
      "Episode =  584total_reward -256.051149705\n",
      "Episode =  585total_reward -508.971819199\n",
      "Episode =  586total_reward -271.442525038\n",
      "Episode =  587total_reward -263.621255377\n",
      "Episode =  588total_reward -256.620282044\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode =  589total_reward -726.886777675\n",
      "Episode =  590total_reward -940.952266016\n",
      "Episode =  591total_reward -267.728338375\n",
      "Episode =  592total_reward -519.912342121\n",
      "Episode =  593total_reward -731.285266164\n",
      "Episode =  594total_reward -481.82728578\n",
      "Episode =  595total_reward -505.448749383\n",
      "Episode =  596total_reward -259.130389757\n",
      "Episode =  597total_reward -504.620696737\n",
      "Episode =  598total_reward -491.165138221\n",
      "Episode =  599total_reward -262.362986708\n",
      "Episode =  600total_reward -507.688203189\n",
      "Episode =  601total_reward -395.317884209\n",
      "Episode =  602total_reward -247.769789413\n",
      "Episode =  603total_reward -460.076309112\n",
      "Episode =  604total_reward -257.291912393\n",
      "Episode =  605total_reward -265.359543939\n",
      "Episode =  606total_reward -264.993679562\n",
      "Episode =  607total_reward -249.432776315\n",
      "Episode =  608total_reward -972.24241469\n",
      "Episode =  609total_reward -654.45564905\n",
      "Episode =  610total_reward -627.309467199\n",
      "Episode =  611total_reward -15.2243986818\n",
      "Episode =  612total_reward -470.263957539\n",
      "Episode =  613total_reward -450.871170556\n",
      "Episode =  614total_reward -31.4516556329\n",
      "Episode =  615total_reward -13.6313313901\n",
      "Episode =  616total_reward -944.559426797\n",
      "Episode =  617total_reward -506.336489723\n",
      "Episode =  618total_reward -254.910033646\n",
      "Episode =  619total_reward -459.038678852\n",
      "Episode =  620total_reward -503.263896031\n",
      "Episode =  621total_reward -258.769908635\n",
      "Episode =  622total_reward -503.692784883\n",
      "Episode =  623total_reward -506.131469675\n",
      "Episode =  624total_reward -484.959383818\n",
      "Episode =  625total_reward -10.9474226139\n",
      "Episode =  626total_reward -760.526657223\n",
      "Episode =  627total_reward -587.845567222\n",
      "Episode =  628total_reward -249.193914439\n",
      "Episode =  629total_reward -14.5254538575\n",
      "Episode =  630total_reward -537.132984091\n",
      "Episode =  631total_reward -780.45559908\n",
      "Episode =  632total_reward -253.702262189\n",
      "Episode =  633total_reward -261.123835286\n",
      "Episode =  634total_reward -260.660124235\n",
      "Episode =  635total_reward -495.925874755\n",
      "Episode =  636total_reward -747.111016903\n",
      "Episode =  637total_reward -13.0355079766\n",
      "Episode =  638total_reward -251.559640951\n",
      "Episode =  639total_reward -250.881345966\n",
      "Episode =  640total_reward -456.150854188\n",
      "Episode =  641total_reward -515.46645214\n",
      "Episode =  642total_reward -265.333190057\n",
      "Episode =  643total_reward -473.164098616\n",
      "Episode =  644total_reward -259.352681698\n",
      "Episode =  645total_reward -482.397246933\n",
      "Episode =  646total_reward -505.431472442\n",
      "Episode =  647total_reward -736.654006418\n",
      "Episode =  648total_reward -261.79668509\n",
      "Episode =  649total_reward -262.638349649\n",
      "Episode =  650total_reward -12.8870291709\n",
      "Episode =  651total_reward -263.388372561\n",
      "Episode =  652total_reward -497.291172028\n",
      "Episode =  653total_reward -13.2278648179\n",
      "Episode =  654total_reward -1017.34864665\n",
      "Episode =  655total_reward -466.811603189\n",
      "Episode =  656total_reward -826.0530451\n",
      "Episode =  657total_reward -507.256294161\n",
      "Episode =  658total_reward -234.272503378\n",
      "Episode =  659total_reward -11.114229784\n",
      "Episode =  660total_reward -1034.09287602\n",
      "Episode =  661total_reward -256.382173151\n",
      "Episode =  662total_reward -490.719266688\n",
      "Episode =  663total_reward -505.479137363\n",
      "Episode =  664total_reward -696.14788837\n",
      "Episode =  665total_reward -13.6868441002\n",
      "Episode =  666total_reward -527.02591211\n",
      "Episode =  667total_reward -259.886718482\n",
      "Episode =  668total_reward -627.725997014\n",
      "Episode =  669total_reward -505.29485067\n",
      "Episode =  670total_reward -747.676981305\n",
      "Episode =  671total_reward -505.423280857\n",
      "Episode =  672total_reward -264.601919322\n",
      "Episode =  673total_reward -614.870486223\n",
      "Episode =  674total_reward -256.744729308\n",
      "Episode =  675total_reward -260.935432935\n",
      "Episode =  676total_reward -512.859028769\n",
      "Episode =  677total_reward -492.654287188\n",
      "Episode =  678total_reward -253.233491227\n",
      "Episode =  679total_reward -260.744289178\n",
      "Episode =  680total_reward -511.572354988\n",
      "Episode =  681total_reward -12.5067809885\n",
      "Episode =  682total_reward -476.178791126\n",
      "Episode =  683total_reward -262.466360607\n",
      "Episode =  684total_reward -10.7388265862\n",
      "Episode =  685total_reward -252.828793432\n",
      "Episode =  686total_reward -509.142886947\n",
      "Episode =  687total_reward -494.679188196\n",
      "Episode =  688total_reward -495.257689349\n",
      "Episode =  689total_reward -11.6825481335\n",
      "Episode =  690total_reward -261.909783147\n",
      "Episode =  691total_reward -518.755591462\n",
      "Episode =  692total_reward -502.814190932\n",
      "Episode =  693total_reward -257.112621184\n",
      "Episode =  694total_reward -713.585687659\n",
      "Episode =  695total_reward -519.831054596\n",
      "Episode =  696total_reward -509.701369853\n",
      "Episode =  697total_reward -264.224129709\n",
      "Episode =  698total_reward -256.636584243\n",
      "Episode =  699total_reward -262.815876076\n",
      "Episode =  700total_reward -12.3531602767\n",
      "Episode =  701total_reward -258.904557064\n",
      "Episode =  702total_reward -501.068092859\n",
      "Episode =  703total_reward -753.958399763\n",
      "Episode =  704total_reward -256.032020385\n",
      "Episode =  705total_reward -10.4528976033\n",
      "Episode =  706total_reward -492.42732336\n",
      "Episode =  707total_reward -250.079077838\n",
      "Episode =  708total_reward -263.959349098\n",
      "Episode =  709total_reward -260.502850231\n",
      "Episode =  710total_reward -246.816422682\n",
      "Episode =  711total_reward -725.092821686\n",
      "Episode =  712total_reward -504.654648176\n",
      "Episode =  713total_reward -587.476168896\n",
      "Episode =  714total_reward -249.141626917\n",
      "Episode =  715total_reward -265.177709083\n",
      "Episode =  716total_reward -485.166532577\n",
      "Episode =  717total_reward -528.076517312\n",
      "Episode =  718total_reward -494.040959054\n",
      "Episode =  719total_reward -8.77052029189\n",
      "Episode =  720total_reward -260.930610366\n",
      "Episode =  721total_reward -261.405334221\n",
      "Episode =  722total_reward -242.050530938\n",
      "Episode =  723total_reward -9.43107364549\n",
      "Episode =  724total_reward -489.81325131\n",
      "Episode =  725total_reward -260.229814062\n",
      "Episode =  726total_reward -481.195648125\n",
      "Episode =  727total_reward -255.378017482\n",
      "Episode =  728total_reward -254.23918551\n",
      "Episode =  729total_reward -262.716115058\n",
      "Episode =  730total_reward -503.177513425\n",
      "Episode =  731total_reward -254.532032966\n",
      "Episode =  732total_reward -515.490637999\n",
      "Episode =  733total_reward -248.567358907\n",
      "Episode =  734total_reward -259.043012771\n",
      "Episode =  735total_reward -258.157144951\n",
      "Episode =  736total_reward -254.937285477\n",
      "Episode =  737total_reward -248.348358963\n",
      "Episode =  738total_reward -261.228509568\n",
      "Episode =  739total_reward -491.949969744\n",
      "Episode =  740total_reward -253.643198111\n",
      "Episode =  741total_reward -245.949701519\n",
      "Episode =  742total_reward -248.529060409\n",
      "Episode =  743total_reward -510.31601553\n",
      "Episode =  744total_reward -514.912278256\n",
      "Episode =  745total_reward -8.37353216695\n",
      "Episode =  746total_reward -490.932279189\n",
      "Episode =  747total_reward -262.624692257\n",
      "Episode =  748total_reward -249.744550538\n",
      "Episode =  749total_reward -535.992893577\n",
      "Episode =  750total_reward -262.681170637\n",
      "Episode =  751total_reward -721.362714577\n",
      "Episode =  752total_reward -11.0475852432\n",
      "Episode =  753total_reward -258.079019835\n",
      "Episode =  754total_reward -256.411977657\n",
      "Episode =  755total_reward -541.106882908\n",
      "Episode =  756total_reward -464.072589291\n",
      "Episode =  757total_reward -707.196579676\n",
      "Episode =  758total_reward -7.56863314062\n",
      "Episode =  759total_reward -238.92183866\n",
      "Episode =  760total_reward -503.76460657\n",
      "Episode =  761total_reward -643.24259392\n",
      "Episode =  762total_reward -254.374895587\n",
      "Episode =  763total_reward -240.018761071\n",
      "Episode =  764total_reward -508.754901951\n",
      "Episode =  765total_reward -498.837617759\n",
      "Episode =  766total_reward -252.43324959\n",
      "Episode =  767total_reward -5.61271740643\n",
      "Episode =  768total_reward -473.625561307\n",
      "Episode =  769total_reward -5.49908783272\n",
      "Episode =  770total_reward -254.841821123\n",
      "Episode =  771total_reward -237.856227275\n",
      "Episode =  772total_reward -989.555906537\n",
      "Episode =  773total_reward -741.010843463\n",
      "Episode =  774total_reward -251.455226375\n",
      "Episode =  775total_reward -264.142522297\n",
      "Episode =  776total_reward -245.250395355\n",
      "Episode =  777total_reward -761.3491179\n",
      "Episode =  778total_reward -474.124427837\n",
      "Episode =  779total_reward -247.944608168\n",
      "Episode =  780total_reward -1054.96500348\n",
      "Episode =  781total_reward -3.67218897304\n",
      "Episode =  782total_reward -7.19406480697\n",
      "Episode =  783total_reward -245.867482463\n",
      "Episode =  784total_reward -255.841410985\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode =  785total_reward -470.121469061\n",
      "Episode =  786total_reward -254.023754661\n",
      "Episode =  787total_reward -472.258269254\n",
      "Episode =  788total_reward -709.897821263\n",
      "Episode =  789total_reward -499.573010268\n",
      "Episode =  790total_reward -474.249227981\n",
      "Episode =  791total_reward -248.269335484\n",
      "Episode =  792total_reward -242.241615448\n",
      "Episode =  793total_reward -742.929935912\n",
      "Episode =  794total_reward -258.794782319\n",
      "Episode =  795total_reward -244.954148954\n",
      "Episode =  796total_reward -552.775817796\n",
      "Episode =  797total_reward -629.752386912\n",
      "Episode =  798total_reward -511.776405241\n",
      "Episode =  799total_reward -241.407075853\n",
      "Episode =  800total_reward -244.940942729\n",
      "Episode =  801total_reward -509.833684998\n",
      "Episode =  802total_reward -248.230835222\n",
      "Episode =  803total_reward -252.579321475\n",
      "Episode =  804total_reward -485.966025917\n",
      "Episode =  805total_reward -531.270397319\n",
      "Episode =  806total_reward -256.221890531\n",
      "Episode =  807total_reward -247.660330292\n",
      "Episode =  808total_reward -726.09531429\n",
      "Episode =  809total_reward -481.444810954\n",
      "Episode =  810total_reward -1.41683518164\n",
      "Episode =  811total_reward -256.952377134\n",
      "Episode =  812total_reward -244.524500585\n",
      "Episode =  813total_reward -230.583449453\n",
      "Episode =  814total_reward -499.740277575\n",
      "Episode =  815total_reward -2.04879260221\n",
      "Episode =  816total_reward -248.251093617\n",
      "Episode =  817total_reward -250.82663013\n",
      "Episode =  818total_reward -509.056899363\n",
      "Episode =  819total_reward -260.759942161\n",
      "Episode =  820total_reward -239.301683858\n",
      "Episode =  821total_reward -737.191989488\n",
      "Episode =  822total_reward -239.440366628\n",
      "Episode =  823total_reward -241.689752231\n",
      "Episode =  824total_reward -260.171568075\n",
      "Episode =  825total_reward -252.221995813\n",
      "Episode =  826total_reward -514.508689212\n",
      "Episode =  827total_reward -249.531342721\n",
      "Episode =  828total_reward -740.27444458\n",
      "Episode =  829total_reward -480.828078594\n",
      "Episode =  830total_reward -725.856272686\n",
      "Episode =  831total_reward -257.332119592\n",
      "Episode =  832total_reward -251.837132465\n",
      "Episode =  833total_reward -1.82810778079\n",
      "Episode =  834total_reward -470.118486549\n",
      "Episode =  835total_reward -256.718059025\n",
      "Episode =  836total_reward -255.403386488\n",
      "Episode =  837total_reward -246.773730169\n",
      "Episode =  838total_reward -507.629363128\n",
      "Episode =  839total_reward -864.192564929\n",
      "Episode =  840total_reward -247.455677615\n",
      "Episode =  841total_reward -748.657155887\n",
      "Episode =  842total_reward -241.329641652\n",
      "Episode =  843total_reward -579.90637045\n",
      "Episode =  844total_reward -476.56741484\n",
      "Episode =  845total_reward -477.810098015\n",
      "Episode =  846total_reward -2.46039446804\n",
      "Episode =  847total_reward -4.38703912098\n",
      "Episode =  848total_reward -3.88016624094\n",
      "Episode =  849total_reward -253.594271873\n",
      "Episode =  850total_reward -513.413052854\n",
      "Episode =  851total_reward -254.161022166\n",
      "Episode =  852total_reward -243.169620976\n",
      "Episode =  853total_reward -250.362685584\n",
      "Episode =  854total_reward -508.263078275\n",
      "Episode =  855total_reward -252.452530387\n",
      "Episode =  856total_reward -1.35790831292\n",
      "Episode =  857total_reward -2.57313322259\n",
      "Episode =  858total_reward -511.879241768\n",
      "Episode =  859total_reward -3.08743360128\n",
      "Episode =  860total_reward -1.73003132081\n",
      "Episode =  861total_reward -933.469078555\n",
      "Episode =  862total_reward -724.334154367\n",
      "Episode =  863total_reward -519.257798643\n",
      "Episode =  864total_reward -243.547495596\n",
      "Episode =  865total_reward -259.4349921\n",
      "Episode =  866total_reward -240.945626883\n",
      "Episode =  867total_reward -253.978075092\n",
      "Episode =  868total_reward -232.158152304\n",
      "Episode =  869total_reward -499.058528403\n",
      "Episode =  870total_reward -575.072228091\n",
      "Episode =  871total_reward -516.807497042\n",
      "Episode =  872total_reward -239.910112029\n",
      "Episode =  873total_reward -492.294287134\n",
      "Episode =  874total_reward -245.84068206\n",
      "Episode =  875total_reward -246.076883365\n",
      "Episode =  876total_reward -253.887163593\n",
      "Episode =  877total_reward -254.84104933\n",
      "Episode =  878total_reward -251.611794555\n",
      "Episode =  879total_reward -739.524948344\n",
      "Episode =  880total_reward -3.04506811495\n",
      "Episode =  881total_reward -743.802924221\n",
      "Episode =  882total_reward -252.685200815\n",
      "Episode =  883total_reward -744.256248549\n",
      "Episode =  884total_reward -240.310901325\n",
      "Episode =  885total_reward -479.137589507\n",
      "Episode =  886total_reward -727.323689224\n",
      "Episode =  887total_reward -724.973150991\n",
      "Episode =  888total_reward -238.299243761\n",
      "Episode =  889total_reward -231.620371753\n",
      "Episode =  890total_reward -236.207204152\n",
      "Episode =  891total_reward -493.509887776\n",
      "Episode =  892total_reward -767.570594368\n",
      "Episode =  893total_reward -234.155546163\n",
      "Episode =  894total_reward -2.29484402646\n",
      "Episode =  895total_reward -584.006718168\n",
      "Episode =  896total_reward -237.007834106\n",
      "Episode =  897total_reward -2.82111733925\n",
      "Episode =  898total_reward -0.947550085229\n",
      "Episode =  899total_reward -244.281873197\n",
      "Episode =  900total_reward -250.861862168\n",
      "Episode =  901total_reward -257.041744568\n",
      "Episode =  902total_reward -243.971878334\n",
      "Episode =  903total_reward -516.949305366\n",
      "Episode =  904total_reward -246.171513912\n",
      "Episode =  905total_reward -233.436349798\n",
      "Episode =  906total_reward -1.74515836782\n",
      "Episode =  907total_reward -249.637998656\n",
      "Episode =  908total_reward -5.26662161727\n",
      "Episode =  909total_reward -246.108521152\n",
      "Episode =  910total_reward -1080.3569036\n",
      "Episode =  911total_reward -496.002212429\n",
      "Episode =  912total_reward -236.645597111\n",
      "Episode =  913total_reward -3.97429701412\n",
      "Episode =  914total_reward -513.149225852\n",
      "Episode =  915total_reward -237.450696737\n",
      "Episode =  916total_reward -3.1516723707\n",
      "Episode =  917total_reward -259.984709365\n",
      "Episode =  918total_reward -241.986019602\n",
      "Episode =  919total_reward -811.573777454\n",
      "Episode =  920total_reward -256.54469173\n",
      "Episode =  921total_reward -3.86279240392\n",
      "Episode =  922total_reward -239.789213449\n",
      "Episode =  923total_reward -252.155439496\n",
      "Episode =  924total_reward -7.43902959755\n",
      "Episode =  925total_reward -2.97045084421\n",
      "Episode =  926total_reward -473.443831525\n",
      "Episode =  927total_reward -248.084094045\n",
      "Episode =  928total_reward -646.091781809\n",
      "Episode =  929total_reward -232.273692436\n",
      "Episode =  930total_reward -227.268855703\n",
      "Episode =  931total_reward -503.059585366\n",
      "Episode =  932total_reward -256.161410273\n",
      "Episode =  933total_reward -241.35957591\n",
      "Episode =  934total_reward -964.208874994\n",
      "Episode =  935total_reward -514.392472511\n",
      "Episode =  936total_reward -672.206657521\n",
      "Episode =  937total_reward -4.82370718906\n",
      "Episode =  938total_reward -251.927064119\n",
      "Episode =  939total_reward -250.138120339\n",
      "Episode =  940total_reward -470.99912709\n",
      "Episode =  941total_reward -465.186457257\n",
      "Episode =  942total_reward -2.45317977909\n",
      "Episode =  943total_reward -463.819925576\n",
      "Episode =  944total_reward -735.89040509\n",
      "Episode =  945total_reward -243.576110784\n",
      "Episode =  946total_reward -489.756205494\n",
      "Episode =  947total_reward -254.614234572\n",
      "Episode =  948total_reward -236.48400161\n",
      "Episode =  949total_reward -4.37647623563\n",
      "Episode =  950total_reward -249.097912065\n",
      "Episode =  951total_reward -767.993283643\n",
      "Episode =  952total_reward -505.963749404\n",
      "Episode =  953total_reward -801.015036744\n",
      "Episode =  954total_reward -239.607450367\n",
      "Episode =  955total_reward -478.950493578\n",
      "Episode =  956total_reward -708.800633384\n",
      "Episode =  957total_reward -262.092895528\n",
      "Episode =  958total_reward -485.309904564\n",
      "Episode =  959total_reward -246.4219106\n",
      "Episode =  960total_reward -246.609815366\n",
      "Episode =  961total_reward -497.236836886\n",
      "Episode =  962total_reward -504.667305421\n",
      "Episode =  963total_reward -749.138560998\n",
      "Episode =  964total_reward -258.446246954\n",
      "Episode =  965total_reward -498.16075816\n",
      "Episode =  966total_reward -248.356994332\n",
      "Episode =  967total_reward -247.026518097\n",
      "Episode =  968total_reward -608.313488692\n",
      "Episode =  969total_reward -4.3294752976\n",
      "Episode =  970total_reward -241.05364205\n",
      "Episode =  971total_reward -255.232519897\n",
      "Episode =  972total_reward -472.249838988\n",
      "Episode =  973total_reward -256.723507748\n",
      "Episode =  974total_reward -242.851811299\n",
      "Episode =  975total_reward -7.87293891742\n",
      "Episode =  976total_reward -903.168423086\n",
      "Episode =  977total_reward -255.651871088\n",
      "Episode =  978total_reward -507.878285741\n",
      "Episode =  979total_reward -241.840094636\n",
      "Episode =  980total_reward -497.275309763\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode =  981total_reward -576.191571826\n",
      "Episode =  982total_reward -258.357955223\n",
      "Episode =  983total_reward -706.581247062\n",
      "Episode =  984total_reward -883.082371901\n",
      "Episode =  985total_reward -708.879339695\n",
      "Episode =  986total_reward -507.826397741\n",
      "Episode =  987total_reward -238.630557337\n",
      "Episode =  988total_reward -250.794811049\n",
      "Episode =  989total_reward -236.301936033\n",
      "Episode =  990total_reward -497.886589961\n",
      "Episode =  991total_reward -266.950727097\n",
      "Episode =  992total_reward -254.869665811\n",
      "Episode =  993total_reward -476.256447745\n",
      "Episode =  994total_reward -502.725361184\n",
      "Episode =  995total_reward -777.484292331\n",
      "Episode =  996total_reward -497.36171221\n",
      "Episode =  997total_reward -704.509034733\n",
      "Episode =  998total_reward -14.8337300366\n",
      "Episode =  999total_reward -740.883397453\n",
      "Episode = 1000total_reward -793.426619434\n",
      "Episode = 1001total_reward -718.382752254\n",
      "Episode = 1002total_reward -247.245397191\n",
      "Episode = 1003total_reward -275.555986951\n",
      "Episode = 1004total_reward -256.831549628\n",
      "Episode = 1005total_reward -250.045686397\n",
      "Episode = 1006total_reward -453.287777185\n",
      "Episode = 1007total_reward -745.153606507\n",
      "Episode = 1008total_reward -259.199522575\n",
      "Episode = 1009total_reward -263.902344636\n",
      "Episode = 1010total_reward -702.65731136\n",
      "Episode = 1011total_reward -523.699389673\n",
      "Episode = 1012total_reward -781.622576906\n",
      "Episode = 1013total_reward -264.182509049\n",
      "Episode = 1014total_reward -741.642768525\n",
      "Episode = 1015total_reward -515.655154793\n",
      "Episode = 1016total_reward -292.676685339\n",
      "Episode = 1017total_reward -260.192252075\n",
      "Episode = 1018total_reward -491.683910902\n",
      "Episode = 1019total_reward -255.847880916\n",
      "Episode = 1020total_reward -455.469206123\n",
      "Episode = 1021total_reward -726.772091608\n",
      "Episode = 1022total_reward -500.930790118\n",
      "Episode = 1023total_reward -242.222745702\n",
      "Episode = 1024total_reward -956.575738671\n",
      "Episode = 1025total_reward -514.621140851\n",
      "Episode = 1026total_reward -532.066391068\n",
      "Episode = 1027total_reward -234.636937762\n",
      "Episode = 1028total_reward -992.6682068\n",
      "Episode = 1029total_reward -499.95570168\n",
      "Episode = 1030total_reward -254.09989741\n",
      "Episode = 1031total_reward -9.14591924882\n",
      "Episode = 1032total_reward -488.602967496\n",
      "Episode = 1033total_reward -759.724735491\n",
      "Episode = 1034total_reward -10.815598568\n",
      "Episode = 1035total_reward -11.5010011353\n",
      "Episode = 1036total_reward -975.828105066\n",
      "Episode = 1037total_reward -8.45066660895\n",
      "Episode = 1038total_reward -256.578538085\n",
      "Episode = 1039total_reward -482.735776801\n",
      "Episode = 1040total_reward -487.710271266\n",
      "Episode = 1041total_reward -267.539401537\n",
      "Episode = 1042total_reward -501.540758838\n",
      "Episode = 1043total_reward -500.348779033\n",
      "Episode = 1044total_reward -489.826194539\n",
      "Episode = 1045total_reward -482.447149441\n",
      "Episode = 1046total_reward -944.116501709\n",
      "Episode = 1047total_reward -256.970926271\n",
      "Episode = 1048total_reward -239.375501219\n",
      "Episode = 1049total_reward -246.394897587\n",
      "Episode = 1050total_reward -506.486415596\n",
      "Episode = 1051total_reward -696.260005307\n",
      "Episode = 1052total_reward -973.853909517\n",
      "Episode = 1053total_reward -842.809673839\n",
      "Episode = 1054total_reward -792.800065018\n",
      "Episode = 1055total_reward -486.785700738\n",
      "Episode = 1056total_reward -492.006133751\n",
      "Episode = 1057total_reward -806.026549227\n",
      "Episode = 1058total_reward -253.95491366\n",
      "Episode = 1059total_reward -501.377572217\n",
      "Episode = 1060total_reward -260.57975273\n",
      "Episode = 1061total_reward -499.852563474\n",
      "Episode = 1062total_reward -706.771611995\n",
      "Episode = 1063total_reward -735.561464378\n",
      "Episode = 1064total_reward -253.179113793\n",
      "Episode = 1065total_reward -714.044773922\n",
      "Episode = 1066total_reward -486.089292985\n",
      "Episode = 1067total_reward -497.492363337\n",
      "Episode = 1068total_reward -299.948012968\n",
      "Episode = 1069total_reward -500.840996637\n",
      "Episode = 1070total_reward -499.572837094\n",
      "Episode = 1071total_reward -264.584845009\n",
      "Episode = 1072total_reward -493.619809155\n",
      "Episode = 1073total_reward -251.183362458\n",
      "Episode = 1074total_reward -15.848111253\n",
      "Episode = 1075total_reward -498.274478598\n",
      "Episode = 1076total_reward -262.884217299\n",
      "Episode = 1077total_reward -485.797891036\n",
      "Episode = 1078total_reward -253.692169871\n",
      "Episode = 1079total_reward -271.035886917\n",
      "Episode = 1080total_reward -259.156137698\n",
      "Episode = 1081total_reward -263.18168202\n",
      "Episode = 1082total_reward -488.541034988\n",
      "Episode = 1083total_reward -280.881596906\n",
      "Episode = 1084total_reward -247.119090237\n",
      "Episode = 1085total_reward -505.580580949\n",
      "Episode = 1086total_reward -476.910899309\n",
      "Episode = 1087total_reward -265.740714001\n",
      "Episode = 1088total_reward -715.938111933\n",
      "Episode = 1089total_reward -245.604571118\n",
      "Episode = 1090total_reward -265.447542633\n",
      "Episode = 1091total_reward -678.144908123\n",
      "Episode = 1092total_reward -69.674112804\n",
      "Episode = 1093total_reward -491.061455481\n",
      "Episode = 1094total_reward -259.530795211\n",
      "Episode = 1095total_reward -255.084297439\n",
      "Episode = 1096total_reward -503.719981589\n",
      "Episode = 1097total_reward -783.014456369\n",
      "Episode = 1098total_reward -258.754048266\n",
      "Episode = 1099total_reward -255.113593767\n",
      "Episode = 1100total_reward -260.375744408\n",
      "Episode = 1101total_reward -253.872563163\n",
      "Episode = 1102total_reward -526.929669821\n",
      "Episode = 1103total_reward -648.202920847\n",
      "Episode = 1104total_reward -715.650608601\n",
      "Episode = 1105total_reward -501.776342807\n",
      "Episode = 1106total_reward -489.230048277\n",
      "Episode = 1107total_reward -259.857045692\n",
      "Episode = 1108total_reward -643.698314626\n",
      "Episode = 1109total_reward -267.766166873\n",
      "Episode = 1110total_reward -257.815643348\n",
      "Episode = 1111total_reward -748.962511364\n",
      "Episode = 1112total_reward -20.4246801943\n",
      "Episode = 1113total_reward -255.509974528\n",
      "Episode = 1114total_reward -529.456140347\n",
      "Episode = 1115total_reward -873.486297304\n",
      "Episode = 1116total_reward -484.580090287\n",
      "Episode = 1117total_reward -493.614244428\n",
      "Episode = 1118total_reward -479.452590714\n",
      "Episode = 1119total_reward -868.197832843\n",
      "Episode = 1120total_reward -481.089308057\n",
      "Episode = 1121total_reward -930.391281917\n",
      "Episode = 1122total_reward -501.898908937\n",
      "Episode = 1123total_reward -957.547352157\n",
      "Episode = 1124total_reward -501.443358079\n",
      "Episode = 1125total_reward -267.010934094\n",
      "Episode = 1126total_reward -477.399577549\n",
      "Episode = 1127total_reward -727.903110888\n",
      "Episode = 1128total_reward -488.434566033\n",
      "Episode = 1129total_reward -488.417805751\n",
      "Episode = 1130total_reward -21.363688238\n",
      "Episode = 1131total_reward -486.885510185\n",
      "Episode = 1132total_reward -259.731675475\n",
      "Episode = 1133total_reward -47.4547615641\n",
      "Episode = 1134total_reward -494.325505254\n",
      "Episode = 1135total_reward -582.721290641\n",
      "Episode = 1136total_reward -500.684393562\n",
      "Episode = 1137total_reward -736.17212037\n",
      "Episode = 1138total_reward -498.18101008\n",
      "Episode = 1139total_reward -22.696709083\n",
      "Episode = 1140total_reward -259.11646734\n",
      "Episode = 1141total_reward -737.060963163\n",
      "Episode = 1142total_reward -628.919211746\n",
      "Episode = 1143total_reward -487.742033661\n",
      "Episode = 1144total_reward -482.068254834\n",
      "Episode = 1145total_reward -244.197386862\n",
      "Episode = 1146total_reward -480.884349304\n",
      "Episode = 1147total_reward -242.12950435\n",
      "Episode = 1148total_reward -262.254091489\n",
      "Episode = 1149total_reward -496.887452211\n",
      "Episode = 1150total_reward -918.692474155\n",
      "Episode = 1151total_reward -743.583809833\n",
      "Episode = 1152total_reward -496.730372625\n",
      "Episode = 1153total_reward -262.803815289\n",
      "Episode = 1154total_reward -491.209892464\n",
      "Episode = 1155total_reward -656.250627212\n",
      "Episode = 1156total_reward -21.1252628571\n",
      "Episode = 1157total_reward -260.086493446\n",
      "Episode = 1158total_reward -763.998415634\n",
      "Episode = 1159total_reward -509.993733231\n",
      "Episode = 1160total_reward -491.517002473\n",
      "Episode = 1161total_reward -758.808260055\n",
      "Episode = 1162total_reward -507.280795586\n",
      "Episode = 1163total_reward -492.235177039\n",
      "Episode = 1164total_reward -923.197663938\n",
      "Episode = 1165total_reward -719.865441011\n",
      "Episode = 1166total_reward -739.629095223\n",
      "Episode = 1167total_reward -497.053226154\n",
      "Episode = 1168total_reward -687.385036791\n",
      "Episode = 1169total_reward -495.992671755\n",
      "Episode = 1170total_reward -258.147660873\n",
      "Episode = 1171total_reward -501.019766081\n",
      "Episode = 1172total_reward -503.41980488\n",
      "Episode = 1173total_reward -455.020348997\n",
      "Episode = 1174total_reward -502.67142786\n",
      "Episode = 1175total_reward -607.806499788\n",
      "Episode = 1176total_reward -509.286687139\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "Episode = 1177total_reward -248.025028659\n"
     ]
    }
   ],
   "source": [
    "## TODO: Train your agent here.\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import csv\n",
    "\n",
    "from agents.agent import DDPG\n",
    "from replaybuffer import ReplayBuffer\n",
    "from actor import ActorNetwork\n",
    "\n",
    "\n",
    "from gymtask import Task\n",
    "\n",
    "train_length = 2000\n",
    "\n",
    "#Taking off Task Is commented here\n",
    "'''\n",
    "from task import Task\n",
    "runtime = 5.                                     # time limit of the episode\n",
    "init_pose = np.array([0.0, 0.0, 0.1, 0.0, 0.0, 0.0])  # initial pose\n",
    "init_velocities = np.array([0.0, 0.0, 0.0])         # initial velocities\n",
    "init_angle_velocities = np.array([0.0, 0.0, 0.0])   # initial angle velocities\n",
    "target_pose = np.array([0.0, 0.0, 10.0])  # target pose\n",
    "task = Task(init_pose, init_velocities, init_angle_velocities, runtime)\n",
    "\n",
    "labels = ['time', 'x', 'y', 'z', 'phi', 'theta', 'psi', 'x_velocity',\n",
    "          'y_velocity', 'z_velocity', 'phi_velocity', 'theta_velocity',\n",
    "          'psi_velocity', 'rotor_speed1', 'rotor_speed2', 'rotor_speed3', 'rotor_speed4']\n",
    "results = {x : [] for x in labels}\n",
    "'''\n",
    "\n",
    "np.random.seed(1234)\n",
    "tf.set_random_seed(1234)\n",
    "    \n",
    "with tf.Session() as sess:\n",
    "\n",
    "    #task = Task(init_pose = init_pose, target_pos=target_pos) \n",
    "    task = Task()\n",
    "    agent = DDPG(task,sess) \n",
    "    \n",
    "    for i_episode in range(1, train_length+1):\n",
    "        state = agent.reset_episode() # start a new episode\n",
    "        total_value = 0\n",
    "        while True:\n",
    "            action = agent.act(state) \n",
    "            next_state, reward, done = task.step(action)\n",
    "            total_value += reward\n",
    "            agent.step(state, action, reward, done, next_state)\n",
    "            state = next_state\n",
    "            total_value += reward\n",
    "            if done:\n",
    "                print(\"\\rEpisode = {:4d}\".format(i_episode), end=\"\")  # [debug]\n",
    "                print(\"total_reward\", total_value)\n",
    "                break\n",
    "        sys.stdout.flush()\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "'''\n",
    "    done = False\n",
    "    file_output = 'data1.txt'                         # file name for saved results\n",
    "    # Run the simulation, and save the results.\n",
    "    with open(file_output, 'w') as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        writer.writerow(labels)\n",
    "        state = agent.reset_episode() # start a new episode\n",
    "        while True:\n",
    "            rotor_speeds = agent.act(state)\n",
    "            print(rotor_speeds)\n",
    "            s, reward, done = task.step(rotor_speeds)\n",
    "            to_write = [task.sim.time] + list(task.sim.pose) + list(task.sim.v) + list(task.sim.angular_v) + list(rotor_speeds)\n",
    "            for ii in range(len(labels)):\n",
    "                results[labels[ii]].append(to_write[ii])\n",
    "            writer.writerow(to_write)\n",
    "            if done:\n",
    "                break\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO: Plot the rewards.\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.plot(results['time'], results['x'], label='x')\n",
    "plt.plot(results['time'], results['y'], label='y')\n",
    "plt.plot(results['time'], results['z'], label='z')\n",
    "plt.legend()\n",
    "_ = plt.ylim()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instructions\n",
    "\n",
    "Take a look at the files in the directory to better understand the structure of the project. \n",
    "\n",
    "- `task.py`: Define your task (environment) in this file.\n",
    "- `agents/`: Folder containing reinforcement learning agents.\n",
    "    - `policy_search.py`: A sample agent has been provided here.\n",
    "    - `agent.py`: Develop your agent here.\n",
    "- `physics_sim.py`: This file contains the simulator for the quadcopter.  **DO NOT MODIFY THIS FILE**.\n",
    "\n",
    "For this project, you will define your own task in `task.py`.  Although we have provided a example task to get you started, you are encouraged to change it.  Later in this notebook, you will learn more about how to amend this file.\n",
    "\n",
    "You will also design a reinforcement learning agent in `agent.py` to complete your chosen task.  \n",
    "\n",
    "You are welcome to create any additional files to help you to organize your code.  For instance, you may find it useful to define a `model.py` file defining any needed neural network architectures.\n",
    "\n",
    "## Controlling the Quadcopter\n",
    "\n",
    "We provide a sample agent in the code cell below to show you how to use the sim to control the quadcopter.  This agent is even simpler than the sample agent that you'll examine (in `agents/policy_search.py`) later in this notebook!\n",
    "\n",
    "The agent controls the quadcopter by setting the revolutions per second on each of its four rotors.  The provided agent in the `Basic_Agent` class below always selects a random action for each of the four rotors.  These four speeds are returned by the `act` method as a list of four floating-point numbers.  \n",
    "\n",
    "For this project, the agent that you will implement in `agents/agent.py` will have a far more intelligent method for selecting actions!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "class Basic_Agent():\n",
    "    def __init__(self, task):\n",
    "        self.task = task\n",
    "    \n",
    "    def act(self):\n",
    "        new_thrust = random.gauss(450., 25.)\n",
    "        return [new_thrust + random.gauss(0., 1.) for x in range(4)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the code cell below to have the agent select actions to control the quadcopter.  \n",
    "\n",
    "Feel free to change the provided values of `runtime`, `init_pose`, `init_velocities`, and `init_angle_velocities` below to change the starting conditions of the quadcopter.\n",
    "\n",
    "The `labels` list below annotates statistics that are saved while running the simulation.  All of this information is saved in a text file `data.txt` and stored in the dictionary `results`.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import csv\n",
    "import numpy as np\n",
    "from task import Task\n",
    "\n",
    "# Modify the values below to give the quadcopter a different starting position.\n",
    "runtime = 5.                                     # time limit of the episode\n",
    "init_pose = np.array([0., 0., 10., 0., 0., 0.])  # initial pose\n",
    "init_velocities = np.array([0., 0., 0.])         # initial velocities\n",
    "init_angle_velocities = np.array([0., 0., 0.])   # initial angle velocities\n",
    "file_output = 'data.txt'                         # file name for saved results\n",
    "\n",
    "# Setup\n",
    "task = Task(init_pose, init_velocities, init_angle_velocities, runtime)\n",
    "agent = Basic_Agent(task)\n",
    "done = False\n",
    "labels = ['time', 'x', 'y', 'z', 'phi', 'theta', 'psi', 'x_velocity',\n",
    "          'y_velocity', 'z_velocity', 'phi_velocity', 'theta_velocity',\n",
    "          'psi_velocity', 'rotor_speed1', 'rotor_speed2', 'rotor_speed3', 'rotor_speed4']\n",
    "results = {x : [] for x in labels}\n",
    "\n",
    "# Run the simulation, and save the results.\n",
    "with open(file_output, 'w') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerow(labels)\n",
    "    while True:\n",
    "        rotor_speeds = agent.act()\n",
    "        _, _, done = task.step(rotor_speeds)\n",
    "        to_write = [task.sim.time] + list(task.sim.pose) + list(task.sim.v) + list(task.sim.angular_v) + list(rotor_speeds)\n",
    "        for ii in range(len(labels)):\n",
    "            results[labels[ii]].append(to_write[ii])\n",
    "        writer.writerow(to_write)\n",
    "        if done:\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the code cell below to visualize how the position of the quadcopter evolved during the simulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.plot(results['time'], results['x'], label='x')\n",
    "plt.plot(results['time'], results['y'], label='y')\n",
    "plt.plot(results['time'], results['z'], label='z')\n",
    "plt.legend()\n",
    "_ = plt.ylim()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next code cell visualizes the velocity of the quadcopter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(results['time'], results['x_velocity'], label='x_hat')\n",
    "plt.plot(results['time'], results['y_velocity'], label='y_hat')\n",
    "plt.plot(results['time'], results['z_velocity'], label='z_hat')\n",
    "plt.legend()\n",
    "_ = plt.ylim()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, you can plot the Euler angles (the rotation of the quadcopter over the $x$-, $y$-, and $z$-axes),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(results['time'], results['phi'], label='phi')\n",
    "plt.plot(results['time'], results['theta'], label='theta')\n",
    "plt.plot(results['time'], results['psi'], label='psi')\n",
    "plt.legend()\n",
    "_ = plt.ylim()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "before plotting the velocities (in radians per second) corresponding to each of the Euler angles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(results['time'], results['phi_velocity'], label='phi_velocity')\n",
    "plt.plot(results['time'], results['theta_velocity'], label='theta_velocity')\n",
    "plt.plot(results['time'], results['psi_velocity'], label='psi_velocity')\n",
    "plt.legend()\n",
    "_ = plt.ylim()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, you can use the code cell below to print the agent's choice of actions.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(results['time'], results['rotor_speed1'], label='Rotor 1 revolutions / second')\n",
    "plt.plot(results['time'], results['rotor_speed2'], label='Rotor 2 revolutions / second')\n",
    "plt.plot(results['time'], results['rotor_speed3'], label='Rotor 3 revolutions / second')\n",
    "plt.plot(results['time'], results['rotor_speed4'], label='Rotor 4 revolutions / second')\n",
    "plt.legend()\n",
    "_ = plt.ylim()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When specifying a task, you will derive the environment state from the simulator.  Run the code cell below to print the values of the following variables at the end of the simulation:\n",
    "- `task.sim.pose` (the position of the quadcopter in ($x,y,z$) dimensions and the Euler angles),\n",
    "- `task.sim.v` (the velocity of the quadcopter in ($x,y,z$) dimensions), and\n",
    "- `task.sim.angular_v` (radians/second for each of the three Euler angles)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the pose, velocity, and angular velocity of the quadcopter at the end of the episode\n",
    "print(task.sim.pose)\n",
    "print(task.sim.v)\n",
    "print(task.sim.angular_v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the sample task in `task.py`, we use the 6-dimensional pose of the quadcopter to construct the state of the environment at each timestep.  However, when amending the task for your purposes, you are welcome to expand the size of the state vector by including the velocity information.  You can use any combination of the pose, velocity, and angular velocity - feel free to tinker here, and construct the state to suit your task.\n",
    "\n",
    "## The Task\n",
    "\n",
    "A sample task has been provided for you in `task.py`.  Open this file in a new window now. \n",
    "\n",
    "The `__init__()` method is used to initialize several variables that are needed to specify the task.  \n",
    "- The simulator is initialized as an instance of the `PhysicsSim` class (from `physics_sim.py`).  \n",
    "- Inspired by the methodology in the original DDPG paper, we make use of action repeats.  For each timestep of the agent, we step the simulation `action_repeats` timesteps.  If you are not familiar with action repeats, please read the **Results** section in [the DDPG paper](https://arxiv.org/abs/1509.02971).\n",
    "- We set the number of elements in the state vector.  For the sample task, we only work with the 6-dimensional pose information.  To set the size of the state (`state_size`), we must take action repeats into account.  \n",
    "- The environment will always have a 4-dimensional action space, with one entry for each rotor (`action_size=4`). You can set the minimum (`action_low`) and maximum (`action_high`) values of each entry here.\n",
    "- The sample task in this provided file is for the agent to reach a target position.  We specify that target position as a variable.\n",
    "\n",
    "The `reset()` method resets the simulator.  The agent should call this method every time the episode ends.  You can see an example of this in the code cell below.\n",
    "\n",
    "The `step()` method is perhaps the most important.  It accepts the agent's choice of action `rotor_speeds`, which is used to prepare the next state to pass on to the agent.  Then, the reward is computed from `get_reward()`.  The episode is considered done if the time limit has been exceeded, or the quadcopter has travelled outside of the bounds of the simulation.\n",
    "\n",
    "In the next section, you will learn how to test the performance of an agent on this task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Agent\n",
    "\n",
    "The sample agent given in `agents/policy_search.py` uses a very simplistic linear policy to directly compute the action vector as a dot product of the state vector and a matrix of weights. Then, it randomly perturbs the parameters by adding some Gaussian noise, to produce a different policy. Based on the average reward obtained in each episode (`score`), it keeps track of the best set of parameters found so far, how the score is changing, and accordingly tweaks a scaling factor to widen or tighten the noise.\n",
    "\n",
    "Run the code cell below to see how the agent performs on the sample task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "from agents.policy_search import PolicySearch_Agent\n",
    "from task import Task\n",
    "\n",
    "num_episodes = 1000\n",
    "target_pos = np.array([0., 0., 10.])\n",
    "task = Task(target_pos=target_pos)\n",
    "agent = PolicySearch_Agent(task) \n",
    "\n",
    "for i_episode in range(1, num_episodes+1):\n",
    "    state = agent.reset_episode() # start a new episode\n",
    "    while True:\n",
    "        action = agent.act(state) \n",
    "        next_state, reward, done = task.step(action)\n",
    "        agent.step(reward, done)\n",
    "        state = next_state\n",
    "        if done:\n",
    "            print(\"\\rEpisode = {:4d}, score = {:7.3f} (best = {:7.3f}), noise_scale = {}\".format(\n",
    "                i_episode, agent.score, agent.best_score, agent.noise_scale), end=\"\")  # [debug]\n",
    "            break\n",
    "    sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This agent should perform very poorly on this task.  And that's where you come in!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Define the Task, Design the Agent, and Train Your Agent!\n",
    "\n",
    "Amend `task.py` to specify a task of your choosing.  If you're unsure what kind of task to specify, you may like to teach your quadcopter to takeoff, hover in place, land softly, or reach a target pose.  \n",
    "\n",
    "After specifying your task, use the sample agent in `agents/policy_search.py` as a template to define your own agent in `agents/agent.py`.  You can borrow whatever you need from the sample agent, including ideas on how you might modularize your code (using helper methods like `act()`, `learn()`, `reset_episode()`, etc.).\n",
    "\n",
    "Note that it is **highly unlikely** that the first agent and task that you specify will learn well.  You will likely have to tweak various hyperparameters and the reward function for your task until you arrive at reasonably good behavior.\n",
    "\n",
    "As you develop your agent, it's important to keep an eye on how it's performing. Use the code above as inspiration to build in a mechanism to log/save the total rewards obtained in each episode to file.  If the episode rewards are gradually increasing, this is an indication that your agent is learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tflearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 1 [ 2.] [-2.]\n",
      "Episode =    1total_reward -1002.35642565\n",
      "Episode =    2total_reward -1676.53515273\n",
      "Episode =    3total_reward -1293.68792629\n",
      "Episode =    4total_reward -1508.07416154\n",
      "Episode =    5total_reward -1293.15228303\n",
      "Episode =    6total_reward -1131.95569578\n",
      "Episode =    7total_reward -1655.72831107\n",
      "Episode =    8total_reward -1714.89180101\n",
      "Episode =    9total_reward -1525.94108247\n",
      "Episode =   10total_reward -1490.04829722\n",
      "Episode =   11total_reward -1396.48413043\n",
      "Episode =   12total_reward -1486.10518655\n",
      "Episode =   13total_reward -1506.89556731\n",
      "Episode =   14total_reward -1493.12985094\n",
      "Episode =   15total_reward -1473.54443791\n",
      "Episode =   16total_reward -1514.05777757\n",
      "Episode =   17total_reward -1512.4287791\n",
      "Episode =   18total_reward -1171.66039719\n",
      "Episode =   19total_reward -1557.2715324\n",
      "Episode =   20total_reward -1479.27292406\n",
      "Episode =   21total_reward -1429.75270209\n",
      "Episode =   22total_reward -1313.38441704\n",
      "Episode =   23total_reward -1492.24515676\n",
      "Episode =   24total_reward -1444.30205595\n",
      "Episode =   25total_reward -905.016082616\n",
      "Episode =   26total_reward -1122.80414593\n",
      "Episode =   27total_reward -1416.75953128\n",
      "Episode =   28total_reward -1539.7773984\n",
      "Episode =   29total_reward -1503.1994692\n",
      "Episode =   30total_reward -1596.77249304\n",
      "Episode =   31total_reward -1462.6413358\n",
      "Episode =   32total_reward -1525.93162238\n",
      "Episode =   33total_reward -1278.22638034\n",
      "Episode =   34total_reward -1431.02111105\n",
      "Episode =   35total_reward -1182.49541257\n",
      "Episode =   36total_reward -1447.04699995\n",
      "Episode =   37total_reward -1225.17002179\n",
      "Episode =   38total_reward -1434.74423006\n",
      "Episode =   39total_reward -1394.4559348\n",
      "Episode =   40total_reward -1516.93835315\n",
      "Episode =   41total_reward -1172.6081283\n",
      "Episode =   42total_reward -1563.18930517\n",
      "Episode =   43total_reward -1056.52258232\n",
      "Episode =   44total_reward -1210.50753386\n",
      "Episode =   45total_reward -896.197427688\n",
      "Episode =   46total_reward -1110.84142769\n",
      "Episode =   47total_reward -1483.90897245\n",
      "Episode =   48total_reward -1349.19079173\n",
      "Episode =   49total_reward -1469.41006154\n",
      "Episode =   50total_reward -886.917443347\n",
      "Episode =   51total_reward -1497.87077716\n",
      "Episode =   52total_reward -1537.76497271\n",
      "Episode =   53total_reward -1523.14543626\n",
      "Episode =   54total_reward -1053.90564375\n",
      "Episode =   55total_reward -1556.54368704\n",
      "Episode =   56total_reward -1395.38014281\n",
      "Episode =   57total_reward -1476.84878639\n",
      "Episode =   58total_reward -1170.05533479\n",
      "Episode =   59total_reward -1525.3941262\n",
      "Episode =   60total_reward -1309.19475025\n",
      "Episode =   61total_reward -1141.70656705\n",
      "Episode =   62total_reward -1484.31561312\n",
      "Episode =   63total_reward -1370.20268503\n",
      "Episode =   64total_reward -991.526405279\n",
      "Episode =   65total_reward -1067.42515577\n",
      "Episode =   66total_reward -278.43059219\n",
      "Episode =   67total_reward -1279.12405051\n",
      "Episode =   68total_reward -1142.27176862\n",
      "Episode =   69total_reward -925.04579184\n",
      "Episode =   70total_reward -1099.41109399\n",
      "Episode =   71total_reward -1515.04041373\n",
      "Episode =   72total_reward -787.577321801\n",
      "Episode =   73total_reward -539.428478775\n",
      "Episode =   74total_reward -975.494845222\n",
      "Episode =   75total_reward -783.826353955\n",
      "Episode =   76total_reward -1181.09483156\n",
      "Episode =   77total_reward -544.776439838\n",
      "Episode =   78total_reward -257.8303576\n",
      "Episode =   79total_reward -824.778155993\n",
      "Episode =   80total_reward -572.942547707\n",
      "Episode =   81total_reward -1231.09243021\n",
      "Episode =   82total_reward -652.75075863\n",
      "Episode =   83total_reward -275.918461164\n",
      "Episode =   84total_reward -1503.1123561\n",
      "Episode =   85total_reward -812.800601151\n",
      "Episode =   86total_reward -541.374441158\n",
      "Episode =   87total_reward -1385.38969131\n",
      "Episode =   88total_reward -773.422459235\n",
      "Episode =   89total_reward -1028.74386477\n",
      "Episode =   90total_reward -520.865062291\n",
      "Episode =   91total_reward -512.789753797\n",
      "Episode =   92total_reward -741.751241521\n",
      "Episode =   93total_reward -264.68789932\n",
      "Episode =   94total_reward -776.441350652\n",
      "Episode =   95total_reward -15.0602735856\n",
      "Episode =   96total_reward -523.366682753\n",
      "Episode =   97total_reward -532.388291741\n",
      "Episode =   98total_reward -564.413999096\n",
      "Episode =   99total_reward -530.18693603\n",
      "Episode =  100total_reward -773.841783311\n",
      "Episode =  101total_reward -1076.35327982\n",
      "Episode =  102total_reward -520.916719532\n",
      "Episode =  103total_reward -777.695811627\n",
      "Episode =  104total_reward -541.015336894\n",
      "Episode =  105total_reward -771.729004755\n",
      "Episode =  106total_reward -519.122111261\n",
      "Episode =  107total_reward -979.203667614\n",
      "Episode =  108total_reward -538.012694253\n",
      "Episode =  109total_reward -518.89423991\n",
      "Episode =  110total_reward -550.300423437\n",
      "Episode =  111total_reward -1078.9962946\n",
      "Episode =  112total_reward -1505.95263833\n",
      "Episode =  113total_reward -1239.47574599\n",
      "Episode =  114total_reward -880.623826089\n",
      "Episode =  115total_reward -519.092991295\n",
      "Episode =  116total_reward -828.709881491\n",
      "Episode =  117total_reward -516.914612882\n",
      "Episode =  118total_reward -265.875788465\n",
      "Episode =  119total_reward -780.259783497\n",
      "Episode =  120total_reward -1532.28238047\n",
      "Episode =  121total_reward -825.395944445\n",
      "Episode =  122total_reward -266.161563016\n",
      "Episode =  123total_reward -1536.00537984\n",
      "Episode =  124total_reward -366.061307651\n",
      "Episode =  125total_reward -786.553963792\n",
      "Episode =  126total_reward -802.404094249\n",
      "Episode =  127total_reward -270.888020568\n",
      "Episode =  128total_reward -513.172511816\n",
      "Episode =  129total_reward -263.005203982\n",
      "Episode =  130total_reward -1080.90747133\n",
      "Episode =  131total_reward -268.444199957\n",
      "Episode =  132total_reward -341.253055075\n",
      "Episode =  133total_reward -806.540773145\n",
      "Episode =  134total_reward -1541.11583228\n",
      "Episode =  135total_reward -765.979230933\n",
      "Episode =  136total_reward -254.392604437\n",
      "Episode =  137total_reward -516.319519027\n",
      "Episode =  138total_reward -8.55230897671\n",
      "Episode =  139total_reward -567.774854096\n",
      "Episode =  140total_reward -584.681730936\n",
      "Episode =  141total_reward -517.951230895\n",
      "Episode =  142total_reward -813.863626344\n",
      "Episode =  143total_reward -535.470219353\n",
      "Episode =  144total_reward -1389.89871589\n",
      "Episode =  145total_reward -1565.30494811\n",
      "Episode =  146total_reward -260.379373855\n",
      "Episode =  147total_reward -503.673057908\n",
      "Episode =  148total_reward -535.136518333\n",
      "Episode =  149total_reward -957.177321058\n",
      "Episode =  150total_reward -262.938734288\n",
      "Episode =  151total_reward -764.111755213\n",
      "Episode =  152total_reward -255.19956042\n",
      "Episode =  153total_reward -1036.19569245\n",
      "Episode =  154total_reward -266.671799444\n",
      "Episode =  155total_reward -1.38378635381\n",
      "Episode =  156total_reward -518.668641963\n",
      "Episode =  157total_reward -542.634327534\n",
      "Episode =  158total_reward -512.725762426\n",
      "Episode =  159total_reward -1415.73852612\n",
      "Episode =  160total_reward -1498.46615003\n",
      "Episode =  161total_reward -800.526099046\n",
      "Episode =  162total_reward -259.493323784\n",
      "Episode =  163total_reward -551.857348713\n",
      "Episode =  164total_reward -257.376495017\n",
      "Episode =  165total_reward -257.339669244\n",
      "Episode =  166total_reward -514.227643489\n",
      "Episode =  167total_reward -1320.00079741\n",
      "Episode =  168total_reward -565.924189651\n",
      "Episode =  169total_reward -430.230583631\n",
      "Episode =  170total_reward -253.884270257\n",
      "Episode =  171total_reward -521.005398839\n",
      "Episode =  172total_reward -257.017384757\n",
      "Episode =  173total_reward -502.605261838\n",
      "Episode =  174total_reward -4.09791736884\n",
      "Episode =  175total_reward -1.30862187575\n",
      "Episode =  176total_reward -607.469297207\n",
      "Episode =  177total_reward -703.049262456\n",
      "Episode =  178total_reward -774.701051566\n",
      "Episode =  179total_reward -4.71726300366\n",
      "Episode =  180total_reward -736.740998282\n",
      "Episode =  181total_reward -256.988761717\n",
      "Episode =  182total_reward -255.226308387\n",
      "Episode =  183total_reward -244.590953395\n",
      "Episode =  184total_reward -760.92543822\n",
      "Episode =  185total_reward -887.924382417\n",
      "Episode =  186total_reward -506.392568321\n",
      "Episode =  187total_reward -510.323928097\n",
      "Episode =  188total_reward -528.552177993\n",
      "Episode =  189total_reward -1361.02017153\n",
      "Episode =  190total_reward -1531.46097539\n",
      "Episode =  191total_reward -1336.67925434\n",
      "Episode =  192total_reward -523.700810789\n",
      "Episode =  193total_reward -541.997968739\n",
      "Episode =  194total_reward -264.557585935\n",
      "Episode =  195total_reward -257.234278275\n",
      "Episode =  196total_reward -492.352770402\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode =  197total_reward -260.694398552\n",
      "Episode =  198total_reward -517.286457836\n",
      "Episode =  199total_reward -473.369055469\n",
      "Episode =  200total_reward -511.94423317\n",
      "Episode =  201total_reward -258.573078515\n",
      "Episode =  202total_reward -248.09363499\n",
      "Episode =  203total_reward -258.070880575\n",
      "Episode =  204total_reward -772.937663836\n",
      "Episode =  205total_reward -519.764337903\n",
      "Episode =  206total_reward -516.227496343\n",
      "Episode =  207total_reward -509.190795118\n",
      "Episode =  208total_reward -731.991058644\n",
      "Episode =  209total_reward -246.344258351\n",
      "Episode =  210total_reward -257.497740234\n",
      "Episode =  211total_reward -258.25867785\n",
      "Episode =  212total_reward -981.850891242\n",
      "Episode =  213total_reward -779.870751476\n",
      "Episode =  214total_reward -262.812164787\n",
      "Episode =  215total_reward -753.327977561\n",
      "Episode =  216total_reward -520.709502421\n",
      "Episode =  217total_reward -505.07434935\n",
      "Episode =  218total_reward -252.28908276\n",
      "Episode =  219total_reward -153.771973594\n",
      "Episode =  220total_reward -349.202518794\n",
      "Episode =  221total_reward -240.626638541\n",
      "Episode =  222total_reward -242.139258328\n",
      "Episode =  223total_reward -774.324377429\n",
      "Episode =  224total_reward -259.524664687\n",
      "Episode =  225total_reward -251.342351158\n",
      "Episode =  226total_reward -669.682254803\n",
      "Episode =  227total_reward -516.161276749\n",
      "Episode =  228total_reward -250.46819683\n",
      "Episode =  229total_reward -251.547671105\n",
      "Episode =  230total_reward -261.403478514\n",
      "Episode =  231total_reward -77.238852792\n",
      "Episode =  232total_reward -252.102325054\n",
      "Episode =  233total_reward -555.245805587\n",
      "Episode =  234total_reward -471.172263989\n",
      "Episode =  235total_reward -489.197783778\n",
      "Episode =  236total_reward -291.221634856\n",
      "Episode =  237total_reward -255.716553756\n",
      "Episode =  238total_reward -491.454610016\n",
      "Episode =  239total_reward -248.820096869\n",
      "Episode =  240total_reward -253.311648193\n",
      "Episode =  241total_reward -240.745510229\n",
      "Episode =  242total_reward -475.756779773\n",
      "Episode =  243total_reward -476.535041402\n",
      "Episode =  244total_reward -247.138932076\n",
      "Episode =  245total_reward -251.013639324\n",
      "Episode =  246total_reward -259.126569961\n",
      "Episode =  247total_reward -252.876410401\n",
      "Episode =  248total_reward -520.002976495\n",
      "Episode =  249total_reward -494.767968446\n",
      "Episode =  250total_reward -254.597248782\n",
      "Episode =  251total_reward -508.823409836\n",
      "Episode =  252total_reward -255.826853692\n",
      "Episode =  253total_reward -245.073064842\n",
      "Episode =  254total_reward -1001.14992675\n",
      "Episode =  255total_reward -253.283731162\n",
      "Episode =  256total_reward -1.31565356683\n",
      "Episode =  257total_reward -243.555937364\n",
      "Episode =  258total_reward -478.290823901\n",
      "Episode =  259total_reward -0.521213186948\n",
      "Episode =  260total_reward -247.054478879\n",
      "Episode =  261total_reward -3.56139873676\n",
      "Episode =  262total_reward -256.1847231\n",
      "Episode =  263total_reward -251.402428476\n",
      "Episode =  264total_reward -237.042893774\n",
      "Episode =  265total_reward -250.074974926\n",
      "Episode =  266total_reward -497.913893184\n",
      "Episode =  267total_reward -237.398650061\n",
      "Episode =  268total_reward -251.211041482\n",
      "Episode =  269total_reward -244.056032573\n",
      "Episode =  270total_reward -247.511543586\n",
      "Episode =  271total_reward -706.099003548\n",
      "Episode =  272total_reward -244.066011836\n",
      "Episode =  273total_reward -252.941295073\n",
      "Episode =  274total_reward -710.364568853\n",
      "Episode =  275total_reward -257.755452671\n",
      "Episode =  276total_reward -251.722516646\n",
      "Episode =  277total_reward -787.963825232\n",
      "Episode =  278total_reward -245.923438433\n",
      "Episode =  279total_reward -10.4752847092\n",
      "Episode =  280total_reward -250.145954831\n",
      "Episode =  281total_reward -255.681663076\n",
      "Episode =  282total_reward -245.277436308\n",
      "Episode =  283total_reward -475.899468613\n",
      "Episode =  284total_reward -1.12271754339\n",
      "Episode =  285total_reward -246.90202707\n",
      "Episode =  286total_reward -255.800205597\n",
      "Episode =  287total_reward -483.542556881\n",
      "Episode =  288total_reward -496.495975883\n",
      "Episode =  289total_reward -246.17295411\n",
      "Episode =  290total_reward -620.441952598\n",
      "Episode =  291total_reward -498.532534833\n",
      "Episode =  292total_reward -244.024217673\n",
      "Episode =  293total_reward -256.337051586\n",
      "Episode =  294total_reward -255.441052634\n",
      "Episode =  295total_reward -476.18715029\n",
      "Episode =  296total_reward -3.73841826934\n",
      "Episode =  297total_reward -250.606840533\n",
      "Episode =  298total_reward -251.437270574\n",
      "Episode =  299total_reward -243.690113324\n",
      "Episode =  300total_reward -820.741298228\n",
      "Episode =  301total_reward -488.414184249\n",
      "Episode =  302total_reward -741.592173332\n",
      "Episode =  303total_reward -255.731492856\n",
      "Episode =  304total_reward -252.106768661\n",
      "Episode =  305total_reward -5.25918546042\n",
      "Episode =  306total_reward -476.401410168\n",
      "Episode =  307total_reward -509.008116209\n",
      "Episode =  308total_reward -750.852501473\n",
      "Episode =  309total_reward -250.32190225\n",
      "Episode =  310total_reward -249.733542826\n",
      "Episode =  311total_reward -247.098595323\n",
      "Episode =  312total_reward -493.825349676\n",
      "Episode =  313total_reward -254.60083412\n",
      "Episode =  314total_reward -239.855643195\n",
      "Episode =  315total_reward -247.260364285\n",
      "Episode =  316total_reward -699.221288524\n",
      "Episode =  317total_reward -489.833889849\n",
      "Episode =  318total_reward -469.266481818\n",
      "Episode =  319total_reward -486.961643734\n",
      "Episode =  320total_reward -509.380644751\n",
      "Episode =  321total_reward -718.775291425\n",
      "Episode =  322total_reward -257.614762894\n",
      "Episode =  323total_reward -6.91347207748\n",
      "Episode =  324total_reward -257.430137018\n",
      "Episode =  325total_reward -13.7636478932\n",
      "Episode =  326total_reward -492.098041604\n",
      "Episode =  327total_reward -440.105084091\n",
      "Episode =  328total_reward -9.89541308075\n",
      "Episode =  329total_reward -250.508732174\n",
      "Episode =  330total_reward -236.80116164\n",
      "Episode =  331total_reward -754.952946072\n",
      "Episode =  332total_reward -724.408126747\n",
      "Episode =  333total_reward -251.375276509\n",
      "Episode =  334total_reward -846.930105633\n",
      "Episode =  335total_reward -253.637865683\n",
      "Episode =  336total_reward -256.524212604\n",
      "Episode =  337total_reward -247.410176665\n",
      "Episode =  338total_reward -240.498666253\n",
      "Episode =  339total_reward -297.20135659\n",
      "Episode =  340total_reward -485.513533071\n",
      "Episode =  341total_reward -475.073535498\n",
      "Episode =  342total_reward -368.278980845\n",
      "Episode =  343total_reward -472.298994073\n",
      "Episode =  344total_reward -249.420397706\n",
      "Episode =  345total_reward -1197.48333756\n",
      "Episode =  346total_reward -486.444913344\n",
      "Episode =  347total_reward -301.371263559\n",
      "Episode =  348total_reward -499.43771154\n",
      "Episode =  349total_reward -506.387317696\n",
      "Episode =  350total_reward -500.810050529\n",
      "Episode =  351total_reward -508.381051546\n",
      "Episode =  352total_reward -520.747989591\n",
      "Episode =  353total_reward -256.651120344\n",
      "Episode =  354total_reward -1552.0634141\n",
      "Episode =  355total_reward -263.356054261\n",
      "Episode =  356total_reward -258.954140782\n",
      "Episode =  357total_reward -256.687901228\n",
      "Episode =  358total_reward -796.418792923\n",
      "Episode =  359total_reward -472.123724152\n",
      "Episode =  360total_reward -235.582056457\n",
      "Episode =  361total_reward -497.475724466\n",
      "Episode =  362total_reward -255.189689503\n",
      "Episode =  363total_reward -242.8335787\n",
      "Episode =  364total_reward -1134.7758271\n",
      "Episode =  365total_reward -260.297678399\n",
      "Episode =  366total_reward -399.688829509\n",
      "Episode =  367total_reward -579.402477518\n",
      "Episode =  368total_reward -245.778664973\n",
      "Episode =  369total_reward -260.668230056\n",
      "Episode =  370total_reward -259.494514726\n",
      "Episode =  371total_reward -360.207330136\n",
      "Episode =  372total_reward -256.383216046\n",
      "Episode =  373total_reward -12.8528775486\n",
      "Episode =  374total_reward -501.573850966\n",
      "Episode =  375total_reward -773.308273921\n",
      "Episode =  376total_reward -254.648333944\n",
      "Episode =  377total_reward -507.782886883\n",
      "Episode =  378total_reward -690.066669626\n",
      "Episode =  379total_reward -513.871487782\n",
      "Episode =  380total_reward -750.909771548\n",
      "Episode =  381total_reward -546.459602392\n",
      "Episode =  382total_reward -516.743754672\n",
      "Episode =  383total_reward -494.520573161\n",
      "Episode =  384total_reward -579.36514794\n",
      "Episode =  385total_reward -262.11972161\n",
      "Episode =  386total_reward -255.291129792\n",
      "Episode =  387total_reward -248.624059529\n",
      "Episode =  388total_reward -959.283869925\n",
      "Episode =  389total_reward -7.2833170705\n",
      "Episode =  390total_reward -774.72416371\n",
      "Episode =  391total_reward -507.445275127\n",
      "Episode =  392total_reward -259.942135\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode =  393total_reward -504.497478006\n",
      "Episode =  394total_reward -256.018770492\n",
      "Episode =  395total_reward -924.398874707\n",
      "Episode =  396total_reward -258.398097706\n",
      "Episode =  397total_reward -252.204378923\n",
      "Episode =  398total_reward -201.506130578\n",
      "Episode =  399total_reward -243.835325159\n",
      "Episode =  400total_reward -1450.45788386\n",
      "Episode =  401total_reward -256.848372975\n",
      "Episode =  402total_reward -231.756522374\n",
      "Episode =  403total_reward -264.050780083\n",
      "Episode =  404total_reward -430.371231857\n",
      "Episode =  405total_reward -265.366128631\n",
      "Episode =  406total_reward -488.685724021\n",
      "Episode =  407total_reward -490.657524028\n",
      "Episode =  408total_reward -251.332741196\n",
      "Episode =  409total_reward -506.37277735\n",
      "Episode =  410total_reward -252.286069491\n",
      "Episode =  411total_reward -261.494130556\n",
      "Episode =  412total_reward -265.611644107\n",
      "Episode =  413total_reward -740.997447432\n",
      "Episode =  414total_reward -253.984369312\n",
      "Episode =  415total_reward -478.808573843\n",
      "Episode =  416total_reward -492.686778669\n",
      "Episode =  417total_reward -739.221910457\n",
      "Episode =  418total_reward -250.418240344\n",
      "Episode =  419total_reward -505.602727587\n",
      "Episode =  420total_reward -717.168885667\n",
      "Episode =  421total_reward -254.813286764\n",
      "Episode =  422total_reward -238.525768598\n",
      "Episode =  423total_reward -238.135933047\n",
      "Episode =  424total_reward -264.106702408\n",
      "Episode =  425total_reward -634.336082969\n",
      "Episode =  426total_reward -262.44311694\n",
      "Episode =  427total_reward -787.790083986\n",
      "Episode =  428total_reward -248.653126761\n",
      "Episode =  429total_reward -250.155803954\n",
      "Episode =  430total_reward -489.232062067\n",
      "Episode =  431total_reward -740.638504821\n",
      "Episode =  432total_reward -488.612555504\n",
      "Episode =  433total_reward -523.304423207\n",
      "Episode =  434total_reward -10.3614856314\n",
      "Episode =  435total_reward -252.296117159\n",
      "Episode =  436total_reward -498.622938983\n",
      "Episode =  437total_reward -514.7060516\n",
      "Episode =  438total_reward -479.618445325\n",
      "Episode =  439total_reward -258.195347486\n",
      "Episode =  440total_reward -436.842609292\n",
      "Episode =  441total_reward -259.598963557\n",
      "Episode =  442total_reward -262.474162398\n",
      "Episode =  443total_reward -496.95243066\n",
      "Episode =  444total_reward -503.607582798\n",
      "Episode =  445total_reward -257.333960039\n",
      "Episode =  446total_reward -509.110093721\n",
      "Episode =  447total_reward -512.526219464\n",
      "Episode =  448total_reward -410.703710305\n",
      "Episode =  449total_reward -730.467793875\n",
      "Episode =  450total_reward -497.210512623\n",
      "Episode =  451total_reward -713.909139538\n",
      "Episode =  452total_reward -272.656323274\n",
      "Episode =  453total_reward -486.317391485\n",
      "Episode =  454total_reward -474.857246878\n",
      "Episode =  455total_reward -510.081073147\n",
      "Episode =  456total_reward -517.452002712\n",
      "Episode =  457total_reward -514.29765839\n",
      "Episode =  458total_reward -265.504464774\n",
      "Episode =  459total_reward -747.538607916\n",
      "Episode =  460total_reward -509.702711405\n",
      "Episode =  461total_reward -500.483193886\n",
      "Episode =  462total_reward -257.942094193\n",
      "Episode =  463total_reward -485.497214558\n",
      "Episode =  464total_reward -732.114173009\n",
      "Episode =  465total_reward -235.746302684\n",
      "Episode =  466total_reward -264.587725004\n",
      "Episode =  467total_reward -500.320586809\n",
      "Episode =  468total_reward -260.131808769\n",
      "Episode =  469total_reward -254.096171783\n",
      "Episode =  470total_reward -506.999820822\n",
      "Episode =  471total_reward -277.995361342\n",
      "Episode =  472total_reward -266.843750251\n",
      "Episode =  473total_reward -9.88496142506\n",
      "Episode =  474total_reward -772.02759443\n",
      "Episode =  475total_reward -490.456764977\n",
      "Episode =  476total_reward -265.300870911\n",
      "Episode =  477total_reward -767.088746322\n",
      "Episode =  478total_reward -483.712324491\n",
      "Episode =  479total_reward -501.944002848\n",
      "Episode =  480total_reward -511.826745633\n",
      "Episode =  481total_reward -499.601304843\n",
      "Episode =  482total_reward -338.136578962\n",
      "Episode =  483total_reward -480.71361844\n",
      "Episode =  484total_reward -244.535807381\n",
      "Episode =  485total_reward -534.662761492\n",
      "Episode =  486total_reward -498.420948135\n",
      "Episode =  487total_reward -752.329396507\n",
      "Episode =  488total_reward -239.622476381\n",
      "Episode =  489total_reward -236.492942018\n",
      "Episode =  490total_reward -13.0470080353\n",
      "Episode =  491total_reward -498.751931687\n",
      "Episode =  492total_reward -234.950067112\n",
      "Episode =  493total_reward -259.255236936\n",
      "Episode =  494total_reward -257.290232668\n",
      "Episode =  495total_reward -740.348543441\n",
      "Episode =  496total_reward -11.5691589918\n",
      "Episode =  497total_reward -740.191870864\n",
      "Episode =  498total_reward -242.645957985\n",
      "Episode =  499total_reward -262.997429251\n",
      "Episode =  500total_reward -506.05302784\n",
      "Episode =  501total_reward -61.2690954499\n",
      "Episode =  502total_reward -571.748424719\n",
      "Episode =  503total_reward -479.383228211\n",
      "Episode =  504total_reward -237.956636599\n",
      "Episode =  505total_reward -504.940751379\n",
      "Episode =  506total_reward -250.678315817\n",
      "Episode =  507total_reward -314.96985616\n",
      "Episode =  508total_reward -380.082575202\n",
      "Episode =  509total_reward -244.328754817\n",
      "Episode =  510total_reward -259.88594478\n",
      "Episode =  511total_reward -14.000446725\n",
      "Episode =  512total_reward -491.614901681\n",
      "Episode =  513total_reward -856.398635006\n",
      "Episode =  514total_reward -724.106846544\n",
      "Episode =  515total_reward -247.004429545\n",
      "Episode =  516total_reward -261.317927374\n",
      "Episode =  517total_reward -246.772399911\n",
      "Episode =  518total_reward -976.301037365\n",
      "Episode =  519total_reward -693.926779509\n",
      "Episode =  520total_reward -512.568064768\n",
      "Episode =  521total_reward -507.216727819\n",
      "Episode =  522total_reward -246.954404784\n",
      "Episode =  523total_reward -504.922138379\n",
      "Episode =  524total_reward -472.509854675\n",
      "Episode =  525total_reward -495.882828112\n",
      "Episode =  526total_reward -235.877539148\n",
      "Episode =  527total_reward -262.021510021\n",
      "Episode =  528total_reward -494.728794776\n",
      "Episode =  529total_reward -764.527597346\n",
      "Episode =  530total_reward -496.476880373\n",
      "Episode =  531total_reward -731.754307337\n",
      "Episode =  532total_reward -472.496674034\n",
      "Episode =  533total_reward -709.305097692\n",
      "Episode =  534total_reward -529.302345864\n",
      "Episode =  535total_reward -540.698329813\n",
      "Episode =  536total_reward -266.79798335\n",
      "Episode =  537total_reward -96.9829220665\n",
      "Episode =  538total_reward -258.415224152\n",
      "Episode =  539total_reward -480.22242746\n",
      "Episode =  540total_reward -488.381122045\n",
      "Episode =  541total_reward -150.43206928\n",
      "Episode =  542total_reward -266.259474826\n",
      "Episode =  543total_reward -507.302385439\n",
      "Episode =  544total_reward -705.850400097\n",
      "Episode =  545total_reward -1000.5477837\n",
      "Episode =  546total_reward -508.917895576\n",
      "Episode =  547total_reward -512.778646435\n",
      "Episode =  548total_reward -464.176845975\n",
      "Episode =  549total_reward -266.084472329\n",
      "Episode =  550total_reward -262.340071529\n",
      "Episode =  551total_reward -491.07494967\n",
      "Episode =  552total_reward -717.547664432\n",
      "Episode =  553total_reward -763.573134847\n",
      "Episode =  554total_reward -259.981250452\n",
      "Episode =  555total_reward -13.5314018422\n",
      "Episode =  556total_reward -266.200129085\n",
      "Episode =  557total_reward -248.589946503\n",
      "Episode =  558total_reward -509.567147175\n",
      "Episode =  559total_reward -726.955685478\n",
      "Episode =  560total_reward -719.185077321\n",
      "Episode =  561total_reward -282.927960079\n",
      "Episode =  562total_reward -514.127539195\n",
      "Episode =  563total_reward -712.655798248\n",
      "Episode =  564total_reward -506.712877623\n",
      "Episode =  565total_reward -13.0327663569\n",
      "Episode =  566total_reward -929.130869431\n",
      "Episode =  567total_reward -242.593639558\n",
      "Episode =  568total_reward -262.811789616\n",
      "Episode =  569total_reward -726.132188187\n",
      "Episode =  570total_reward -266.077563732\n",
      "Episode =  571total_reward -259.751670427\n",
      "Episode =  572total_reward -255.752327478\n",
      "Episode =  573total_reward -485.123365144\n",
      "Episode =  574total_reward -257.505667596\n",
      "Episode =  575total_reward -501.33682393\n",
      "Episode =  576total_reward -264.310445531\n",
      "Episode =  577total_reward -673.273205327\n",
      "Episode =  578total_reward -747.994307096\n",
      "Episode =  579total_reward -498.007429191\n",
      "Episode =  580total_reward -517.032197087\n",
      "Episode =  581total_reward -788.839703504\n",
      "Episode =  582total_reward -255.519980368\n",
      "Episode =  583total_reward -175.086408032\n",
      "Episode =  584total_reward -256.051149705\n",
      "Episode =  585total_reward -508.971819199\n",
      "Episode =  586total_reward -271.442525038\n",
      "Episode =  587total_reward -263.621255377\n",
      "Episode =  588total_reward -256.620282044\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode =  589total_reward -726.886777675\n",
      "Episode =  590total_reward -940.952266016\n",
      "Episode =  591total_reward -267.728338375\n",
      "Episode =  592total_reward -519.912342121\n",
      "Episode =  593total_reward -731.285266164\n",
      "Episode =  594total_reward -481.82728578\n",
      "Episode =  595total_reward -505.448749383\n",
      "Episode =  596total_reward -259.130389757\n",
      "Episode =  597total_reward -504.620696737\n",
      "Episode =  598total_reward -491.165138221\n",
      "Episode =  599total_reward -262.362986708\n",
      "Episode =  600total_reward -507.688203189\n",
      "Episode =  601total_reward -395.317884209\n",
      "Episode =  602total_reward -247.769789413\n",
      "Episode =  603total_reward -460.076309112\n",
      "Episode =  604total_reward -257.291912393\n",
      "Episode =  605total_reward -265.359543939\n",
      "Episode =  606total_reward -264.993679562\n",
      "Episode =  607total_reward -249.432776315\n",
      "Episode =  608total_reward -972.24241469\n",
      "Episode =  609total_reward -654.45564905\n",
      "Episode =  610total_reward -627.309467199\n",
      "Episode =  611total_reward -15.2243986818\n",
      "Episode =  612total_reward -470.263957539\n",
      "Episode =  613total_reward -450.871170556\n",
      "Episode =  614total_reward -31.4516556329\n",
      "Episode =  615total_reward -13.6313313901\n",
      "Episode =  616total_reward -944.559426797\n",
      "Episode =  617total_reward -506.336489723\n",
      "Episode =  618total_reward -254.910033646\n",
      "Episode =  619total_reward -459.038678852\n",
      "Episode =  620total_reward -503.263896031\n",
      "Episode =  621total_reward -258.769908635\n",
      "Episode =  622total_reward -503.692784883\n",
      "Episode =  623total_reward -506.131469675\n",
      "Episode =  624total_reward -484.959383818\n",
      "Episode =  625total_reward -10.9474226139\n",
      "Episode =  626total_reward -760.526657223\n",
      "Episode =  627total_reward -587.845567222\n",
      "Episode =  628total_reward -249.193914439\n",
      "Episode =  629total_reward -14.5254538575\n",
      "Episode =  630total_reward -537.132984091\n",
      "Episode =  631total_reward -780.45559908\n",
      "Episode =  632total_reward -253.702262189\n",
      "Episode =  633total_reward -261.123835286\n",
      "Episode =  634total_reward -260.660124235\n",
      "Episode =  635total_reward -495.925874755\n",
      "Episode =  636total_reward -747.111016903\n",
      "Episode =  637total_reward -13.0355079766\n",
      "Episode =  638total_reward -251.559640951\n",
      "Episode =  639total_reward -250.881345966\n",
      "Episode =  640total_reward -456.150854188\n",
      "Episode =  641total_reward -515.46645214\n",
      "Episode =  642total_reward -265.333190057\n",
      "Episode =  643total_reward -473.164098616\n",
      "Episode =  644total_reward -259.352681698\n",
      "Episode =  645total_reward -482.397246933\n",
      "Episode =  646total_reward -505.431472442\n",
      "Episode =  647total_reward -736.654006418\n",
      "Episode =  648total_reward -261.79668509\n",
      "Episode =  649total_reward -262.638349649\n",
      "Episode =  650total_reward -12.8870291709\n",
      "Episode =  651total_reward -263.388372561\n",
      "Episode =  652total_reward -497.291172028\n",
      "Episode =  653total_reward -13.2278648179\n",
      "Episode =  654total_reward -1017.34864665\n",
      "Episode =  655total_reward -466.811603189\n",
      "Episode =  656total_reward -826.0530451\n",
      "Episode =  657total_reward -507.256294161\n",
      "Episode =  658total_reward -234.272503378\n",
      "Episode =  659total_reward -11.114229784\n",
      "Episode =  660total_reward -1034.09287602\n",
      "Episode =  661total_reward -256.382173151\n",
      "Episode =  662total_reward -490.719266688\n",
      "Episode =  663total_reward -505.479137363\n",
      "Episode =  664total_reward -696.14788837\n",
      "Episode =  665total_reward -13.6868441002\n",
      "Episode =  666total_reward -527.02591211\n",
      "Episode =  667total_reward -259.886718482\n",
      "Episode =  668total_reward -627.725997014\n",
      "Episode =  669total_reward -505.29485067\n",
      "Episode =  670total_reward -747.676981305\n",
      "Episode =  671total_reward -505.423280857\n",
      "Episode =  672total_reward -264.601919322\n",
      "Episode =  673total_reward -614.870486223\n",
      "Episode =  674total_reward -256.744729308\n",
      "Episode =  675total_reward -260.935432935\n",
      "Episode =  676total_reward -512.859028769\n",
      "Episode =  677total_reward -492.654287188\n",
      "Episode =  678total_reward -253.233491227\n",
      "Episode =  679total_reward -260.744289178\n",
      "Episode =  680total_reward -511.572354988\n",
      "Episode =  681total_reward -12.5067809885\n",
      "Episode =  682total_reward -476.178791126\n",
      "Episode =  683total_reward -262.466360607\n",
      "Episode =  684total_reward -10.7388265862\n",
      "Episode =  685total_reward -252.828793432\n",
      "Episode =  686total_reward -509.142886947\n",
      "Episode =  687total_reward -494.679188196\n",
      "Episode =  688total_reward -495.257689349\n",
      "Episode =  689total_reward -11.6825481335\n",
      "Episode =  690total_reward -261.909783147\n",
      "Episode =  691total_reward -518.755591462\n",
      "Episode =  692total_reward -502.814190932\n",
      "Episode =  693total_reward -257.112621184\n",
      "Episode =  694total_reward -713.585687659\n",
      "Episode =  695total_reward -519.831054596\n",
      "Episode =  696total_reward -509.701369853\n",
      "Episode =  697total_reward -264.224129709\n",
      "Episode =  698total_reward -256.636584243\n",
      "Episode =  699total_reward -262.815876076\n",
      "Episode =  700total_reward -12.3531602767\n",
      "Episode =  701total_reward -258.904557064\n",
      "Episode =  702total_reward -501.068092859\n",
      "Episode =  703total_reward -753.958399763\n",
      "Episode =  704total_reward -256.032020385\n",
      "Episode =  705total_reward -10.4528976033\n",
      "Episode =  706total_reward -492.42732336\n",
      "Episode =  707total_reward -250.079077838\n",
      "Episode =  708total_reward -263.959349098\n",
      "Episode =  709total_reward -260.502850231\n",
      "Episode =  710total_reward -246.816422682\n",
      "Episode =  711total_reward -725.092821686\n",
      "Episode =  712total_reward -504.654648176\n",
      "Episode =  713total_reward -587.476168896\n",
      "Episode =  714total_reward -249.141626917\n",
      "Episode =  715total_reward -265.177709083\n",
      "Episode =  716total_reward -485.166532577\n",
      "Episode =  717total_reward -528.076517312\n",
      "Episode =  718total_reward -494.040959054\n",
      "Episode =  719total_reward -8.77052029189\n",
      "Episode =  720total_reward -260.930610366\n",
      "Episode =  721total_reward -261.405334221\n",
      "Episode =  722total_reward -242.050530938\n",
      "Episode =  723total_reward -9.43107364549\n",
      "Episode =  724total_reward -489.81325131\n",
      "Episode =  725total_reward -260.229814062\n",
      "Episode =  726total_reward -481.195648125\n",
      "Episode =  727total_reward -255.378017482\n",
      "Episode =  728total_reward -254.23918551\n",
      "Episode =  729total_reward -262.716115058\n",
      "Episode =  730total_reward -503.177513425\n",
      "Episode =  731total_reward -254.532032966\n",
      "Episode =  732total_reward -515.490637999\n",
      "Episode =  733total_reward -248.567358907\n",
      "Episode =  734total_reward -259.043012771\n",
      "Episode =  735total_reward -258.157144951\n",
      "Episode =  736total_reward -254.937285477\n",
      "Episode =  737total_reward -248.348358963\n",
      "Episode =  738total_reward -261.228509568\n",
      "Episode =  739total_reward -491.949969744\n",
      "Episode =  740total_reward -253.643198111\n",
      "Episode =  741total_reward -245.949701519\n",
      "Episode =  742total_reward -248.529060409\n",
      "Episode =  743total_reward -510.31601553\n",
      "Episode =  744total_reward -514.912278256\n",
      "Episode =  745total_reward -8.37353216695\n",
      "Episode =  746total_reward -490.932279189\n",
      "Episode =  747total_reward -262.624692257\n",
      "Episode =  748total_reward -249.744550538\n",
      "Episode =  749total_reward -535.992893577\n",
      "Episode =  750total_reward -262.681170637\n",
      "Episode =  751total_reward -721.362714577\n",
      "Episode =  752total_reward -11.0475852432\n",
      "Episode =  753total_reward -258.079019835\n",
      "Episode =  754total_reward -256.411977657\n",
      "Episode =  755total_reward -541.106882908\n",
      "Episode =  756total_reward -464.072589291\n",
      "Episode =  757total_reward -707.196579676\n",
      "Episode =  758total_reward -7.56863314062\n",
      "Episode =  759total_reward -238.92183866\n",
      "Episode =  760total_reward -503.76460657\n",
      "Episode =  761total_reward -643.24259392\n",
      "Episode =  762total_reward -254.374895587\n",
      "Episode =  763total_reward -240.018761071\n",
      "Episode =  764total_reward -508.754901951\n",
      "Episode =  765total_reward -498.837617759\n",
      "Episode =  766total_reward -252.43324959\n",
      "Episode =  767total_reward -5.61271740643\n",
      "Episode =  768total_reward -473.625561307\n",
      "Episode =  769total_reward -5.49908783272\n",
      "Episode =  770total_reward -254.841821123\n",
      "Episode =  771total_reward -237.856227275\n",
      "Episode =  772total_reward -989.555906537\n",
      "Episode =  773total_reward -741.010843463\n",
      "Episode =  774total_reward -251.455226375\n",
      "Episode =  775total_reward -264.142522297\n",
      "Episode =  776total_reward -245.250395355\n",
      "Episode =  777total_reward -761.3491179\n",
      "Episode =  778total_reward -474.124427837\n",
      "Episode =  779total_reward -247.944608168\n",
      "Episode =  780total_reward -1054.96500348\n",
      "Episode =  781total_reward -3.67218897304\n",
      "Episode =  782total_reward -7.19406480697\n",
      "Episode =  783total_reward -245.867482463\n",
      "Episode =  784total_reward -255.841410985\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode =  785total_reward -470.121469061\n",
      "Episode =  786total_reward -254.023754661\n",
      "Episode =  787total_reward -472.258269254\n",
      "Episode =  788total_reward -709.897821263\n",
      "Episode =  789total_reward -499.573010268\n",
      "Episode =  790total_reward -474.249227981\n",
      "Episode =  791total_reward -248.269335484\n",
      "Episode =  792total_reward -242.241615448\n",
      "Episode =  793total_reward -742.929935912\n",
      "Episode =  794total_reward -258.794782319\n",
      "Episode =  795total_reward -244.954148954\n",
      "Episode =  796total_reward -552.775817796\n",
      "Episode =  797total_reward -629.752386912\n",
      "Episode =  798total_reward -511.776405241\n",
      "Episode =  799total_reward -241.407075853\n",
      "Episode =  800total_reward -244.940942729\n",
      "Episode =  801total_reward -509.833684998\n",
      "Episode =  802total_reward -248.230835222\n",
      "Episode =  803total_reward -252.579321475\n",
      "Episode =  804total_reward -485.966025917\n",
      "Episode =  805total_reward -531.270397319\n",
      "Episode =  806total_reward -256.221890531\n",
      "Episode =  807total_reward -247.660330292\n",
      "Episode =  808total_reward -726.09531429\n",
      "Episode =  809total_reward -481.444810954\n",
      "Episode =  810total_reward -1.41683518164\n",
      "Episode =  811total_reward -256.952377134\n",
      "Episode =  812total_reward -244.524500585\n",
      "Episode =  813total_reward -230.583449453\n",
      "Episode =  814total_reward -499.740277575\n",
      "Episode =  815total_reward -2.04879260221\n",
      "Episode =  816total_reward -248.251093617\n",
      "Episode =  817total_reward -250.82663013\n",
      "Episode =  818total_reward -509.056899363\n",
      "Episode =  819total_reward -260.759942161\n",
      "Episode =  820total_reward -239.301683858\n",
      "Episode =  821total_reward -737.191989488\n",
      "Episode =  822total_reward -239.440366628\n",
      "Episode =  823total_reward -241.689752231\n",
      "Episode =  824total_reward -260.171568075\n",
      "Episode =  825total_reward -252.221995813\n",
      "Episode =  826total_reward -514.508689212\n",
      "Episode =  827total_reward -249.531342721\n",
      "Episode =  828total_reward -740.27444458\n",
      "Episode =  829total_reward -480.828078594\n",
      "Episode =  830total_reward -725.856272686\n",
      "Episode =  831total_reward -257.332119592\n",
      "Episode =  832total_reward -251.837132465\n",
      "Episode =  833total_reward -1.82810778079\n",
      "Episode =  834total_reward -470.118486549\n",
      "Episode =  835total_reward -256.718059025\n",
      "Episode =  836total_reward -255.403386488\n",
      "Episode =  837total_reward -246.773730169\n",
      "Episode =  838total_reward -507.629363128\n",
      "Episode =  839total_reward -864.192564929\n",
      "Episode =  840total_reward -247.455677615\n",
      "Episode =  841total_reward -748.657155887\n",
      "Episode =  842total_reward -241.329641652\n",
      "Episode =  843total_reward -579.90637045\n",
      "Episode =  844total_reward -476.56741484\n",
      "Episode =  845total_reward -477.810098015\n",
      "Episode =  846total_reward -2.46039446804\n",
      "Episode =  847total_reward -4.38703912098\n",
      "Episode =  848total_reward -3.88016624094\n",
      "Episode =  849total_reward -253.594271873\n",
      "Episode =  850total_reward -513.413052854\n",
      "Episode =  851total_reward -254.161022166\n",
      "Episode =  852total_reward -243.169620976\n",
      "Episode =  853total_reward -250.362685584\n",
      "Episode =  854total_reward -508.263078275\n",
      "Episode =  855total_reward -252.452530387\n",
      "Episode =  856total_reward -1.35790831292\n",
      "Episode =  857total_reward -2.57313322259\n",
      "Episode =  858total_reward -511.879241768\n",
      "Episode =  859total_reward -3.08743360128\n",
      "Episode =  860total_reward -1.73003132081\n",
      "Episode =  861total_reward -933.469078555\n",
      "Episode =  862total_reward -724.334154367\n",
      "Episode =  863total_reward -519.257798643\n",
      "Episode =  864total_reward -243.547495596\n",
      "Episode =  865total_reward -259.4349921\n",
      "Episode =  866total_reward -240.945626883\n",
      "Episode =  867total_reward -253.978075092\n",
      "Episode =  868total_reward -232.158152304\n",
      "Episode =  869total_reward -499.058528403\n",
      "Episode =  870total_reward -575.072228091\n",
      "Episode =  871total_reward -516.807497042\n",
      "Episode =  872total_reward -239.910112029\n",
      "Episode =  873total_reward -492.294287134\n",
      "Episode =  874total_reward -245.84068206\n",
      "Episode =  875total_reward -246.076883365\n",
      "Episode =  876total_reward -253.887163593\n",
      "Episode =  877total_reward -254.84104933\n",
      "Episode =  878total_reward -251.611794555\n",
      "Episode =  879total_reward -739.524948344\n",
      "Episode =  880total_reward -3.04506811495\n",
      "Episode =  881total_reward -743.802924221\n",
      "Episode =  882total_reward -252.685200815\n",
      "Episode =  883total_reward -744.256248549\n",
      "Episode =  884total_reward -240.310901325\n",
      "Episode =  885total_reward -479.137589507\n",
      "Episode =  886total_reward -727.323689224\n",
      "Episode =  887total_reward -724.973150991\n",
      "Episode =  888total_reward -238.299243761\n",
      "Episode =  889total_reward -231.620371753\n",
      "Episode =  890total_reward -236.207204152\n",
      "Episode =  891total_reward -493.509887776\n",
      "Episode =  892total_reward -767.570594368\n",
      "Episode =  893total_reward -234.155546163\n",
      "Episode =  894total_reward -2.29484402646\n",
      "Episode =  895total_reward -584.006718168\n",
      "Episode =  896total_reward -237.007834106\n",
      "Episode =  897total_reward -2.82111733925\n",
      "Episode =  898total_reward -0.947550085229\n",
      "Episode =  899total_reward -244.281873197\n",
      "Episode =  900total_reward -250.861862168\n",
      "Episode =  901total_reward -257.041744568\n",
      "Episode =  902total_reward -243.971878334\n",
      "Episode =  903total_reward -516.949305366\n",
      "Episode =  904total_reward -246.171513912\n",
      "Episode =  905total_reward -233.436349798\n",
      "Episode =  906total_reward -1.74515836782\n",
      "Episode =  907total_reward -249.637998656\n",
      "Episode =  908total_reward -5.26662161727\n",
      "Episode =  909total_reward -246.108521152\n",
      "Episode =  910total_reward -1080.3569036\n",
      "Episode =  911total_reward -496.002212429\n",
      "Episode =  912total_reward -236.645597111\n",
      "Episode =  913total_reward -3.97429701412\n",
      "Episode =  914total_reward -513.149225852\n",
      "Episode =  915total_reward -237.450696737\n",
      "Episode =  916total_reward -3.1516723707\n",
      "Episode =  917total_reward -259.984709365\n",
      "Episode =  918total_reward -241.986019602\n",
      "Episode =  919total_reward -811.573777454\n",
      "Episode =  920total_reward -256.54469173\n",
      "Episode =  921total_reward -3.86279240392\n",
      "Episode =  922total_reward -239.789213449\n",
      "Episode =  923total_reward -252.155439496\n",
      "Episode =  924total_reward -7.43902959755\n",
      "Episode =  925total_reward -2.97045084421\n",
      "Episode =  926total_reward -473.443831525\n",
      "Episode =  927total_reward -248.084094045\n",
      "Episode =  928total_reward -646.091781809\n",
      "Episode =  929total_reward -232.273692436\n",
      "Episode =  930total_reward -227.268855703\n",
      "Episode =  931total_reward -503.059585366\n",
      "Episode =  932total_reward -256.161410273\n",
      "Episode =  933total_reward -241.35957591\n",
      "Episode =  934total_reward -964.208874994\n",
      "Episode =  935total_reward -514.392472511\n",
      "Episode =  936total_reward -672.206657521\n",
      "Episode =  937total_reward -4.82370718906\n",
      "Episode =  938total_reward -251.927064119\n",
      "Episode =  939total_reward -250.138120339\n",
      "Episode =  940total_reward -470.99912709\n",
      "Episode =  941total_reward -465.186457257\n",
      "Episode =  942total_reward -2.45317977909\n",
      "Episode =  943total_reward -463.819925576\n",
      "Episode =  944total_reward -735.89040509\n",
      "Episode =  945total_reward -243.576110784\n",
      "Episode =  946total_reward -489.756205494\n",
      "Episode =  947total_reward -254.614234572\n",
      "Episode =  948total_reward -236.48400161\n",
      "Episode =  949total_reward -4.37647623563\n",
      "Episode =  950total_reward -249.097912065\n",
      "Episode =  951total_reward -767.993283643\n",
      "Episode =  952total_reward -505.963749404\n",
      "Episode =  953total_reward -801.015036744\n",
      "Episode =  954total_reward -239.607450367\n",
      "Episode =  955total_reward -478.950493578\n",
      "Episode =  956total_reward -708.800633384\n",
      "Episode =  957total_reward -262.092895528\n",
      "Episode =  958total_reward -485.309904564\n",
      "Episode =  959total_reward -246.4219106\n",
      "Episode =  960total_reward -246.609815366\n",
      "Episode =  961total_reward -497.236836886\n",
      "Episode =  962total_reward -504.667305421\n",
      "Episode =  963total_reward -749.138560998\n",
      "Episode =  964total_reward -258.446246954\n",
      "Episode =  965total_reward -498.16075816\n",
      "Episode =  966total_reward -248.356994332\n",
      "Episode =  967total_reward -247.026518097\n",
      "Episode =  968total_reward -608.313488692\n",
      "Episode =  969total_reward -4.3294752976\n",
      "Episode =  970total_reward -241.05364205\n",
      "Episode =  971total_reward -255.232519897\n",
      "Episode =  972total_reward -472.249838988\n",
      "Episode =  973total_reward -256.723507748\n",
      "Episode =  974total_reward -242.851811299\n",
      "Episode =  975total_reward -7.87293891742\n",
      "Episode =  976total_reward -903.168423086\n",
      "Episode =  977total_reward -255.651871088\n",
      "Episode =  978total_reward -507.878285741\n",
      "Episode =  979total_reward -241.840094636\n",
      "Episode =  980total_reward -497.275309763\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode =  981total_reward -576.191571826\n",
      "Episode =  982total_reward -258.357955223\n",
      "Episode =  983total_reward -706.581247062\n",
      "Episode =  984total_reward -883.082371901\n",
      "Episode =  985total_reward -708.879339695\n",
      "Episode =  986total_reward -507.826397741\n",
      "Episode =  987total_reward -238.630557337\n",
      "Episode =  988total_reward -250.794811049\n",
      "Episode =  989total_reward -236.301936033\n",
      "Episode =  990total_reward -497.886589961\n",
      "Episode =  991total_reward -266.950727097\n",
      "Episode =  992total_reward -254.869665811\n",
      "Episode =  993total_reward -476.256447745\n",
      "Episode =  994total_reward -502.725361184\n",
      "Episode =  995total_reward -777.484292331\n",
      "Episode =  996total_reward -497.36171221\n",
      "Episode =  997total_reward -704.509034733\n",
      "Episode =  998total_reward -14.8337300366\n",
      "Episode =  999total_reward -740.883397453\n",
      "Episode = 1000total_reward -793.426619434\n",
      "Episode = 1001total_reward -718.382752254\n",
      "Episode = 1002total_reward -247.245397191\n",
      "Episode = 1003total_reward -275.555986951\n",
      "Episode = 1004total_reward -256.831549628\n",
      "Episode = 1005total_reward -250.045686397\n",
      "Episode = 1006total_reward -453.287777185\n",
      "Episode = 1007total_reward -745.153606507\n",
      "Episode = 1008total_reward -259.199522575\n",
      "Episode = 1009total_reward -263.902344636\n",
      "Episode = 1010total_reward -702.65731136\n",
      "Episode = 1011total_reward -523.699389673\n",
      "Episode = 1012total_reward -781.622576906\n",
      "Episode = 1013total_reward -264.182509049\n",
      "Episode = 1014total_reward -741.642768525\n",
      "Episode = 1015total_reward -515.655154793\n",
      "Episode = 1016total_reward -292.676685339\n",
      "Episode = 1017total_reward -260.192252075\n",
      "Episode = 1018total_reward -491.683910902\n",
      "Episode = 1019total_reward -255.847880916\n",
      "Episode = 1020total_reward -455.469206123\n",
      "Episode = 1021total_reward -726.772091608\n",
      "Episode = 1022total_reward -500.930790118\n",
      "Episode = 1023total_reward -242.222745702\n",
      "Episode = 1024total_reward -956.575738671\n",
      "Episode = 1025total_reward -514.621140851\n",
      "Episode = 1026total_reward -532.066391068\n",
      "Episode = 1027total_reward -234.636937762\n",
      "Episode = 1028total_reward -992.6682068\n",
      "Episode = 1029total_reward -499.95570168\n",
      "Episode = 1030total_reward -254.09989741\n",
      "Episode = 1031total_reward -9.14591924882\n",
      "Episode = 1032total_reward -488.602967496\n",
      "Episode = 1033total_reward -759.724735491\n",
      "Episode = 1034total_reward -10.815598568\n",
      "Episode = 1035total_reward -11.5010011353\n",
      "Episode = 1036total_reward -975.828105066\n",
      "Episode = 1037total_reward -8.45066660895\n",
      "Episode = 1038total_reward -256.578538085\n",
      "Episode = 1039total_reward -482.735776801\n",
      "Episode = 1040total_reward -487.710271266\n",
      "Episode = 1041total_reward -267.539401537\n",
      "Episode = 1042total_reward -501.540758838\n",
      "Episode = 1043total_reward -500.348779033\n",
      "Episode = 1044total_reward -489.826194539\n",
      "Episode = 1045total_reward -482.447149441\n",
      "Episode = 1046total_reward -944.116501709\n",
      "Episode = 1047total_reward -256.970926271\n",
      "Episode = 1048total_reward -239.375501219\n",
      "Episode = 1049total_reward -246.394897587\n",
      "Episode = 1050total_reward -506.486415596\n",
      "Episode = 1051total_reward -696.260005307\n",
      "Episode = 1052total_reward -973.853909517\n",
      "Episode = 1053total_reward -842.809673839\n",
      "Episode = 1054total_reward -792.800065018\n",
      "Episode = 1055total_reward -486.785700738\n",
      "Episode = 1056total_reward -492.006133751\n",
      "Episode = 1057total_reward -806.026549227\n",
      "Episode = 1058total_reward -253.95491366\n",
      "Episode = 1059total_reward -501.377572217\n",
      "Episode = 1060total_reward -260.57975273\n",
      "Episode = 1061total_reward -499.852563474\n",
      "Episode = 1062total_reward -706.771611995\n",
      "Episode = 1063total_reward -735.561464378\n",
      "Episode = 1064total_reward -253.179113793\n",
      "Episode = 1065total_reward -714.044773922\n",
      "Episode = 1066total_reward -486.089292985\n",
      "Episode = 1067total_reward -497.492363337\n",
      "Episode = 1068total_reward -299.948012968\n",
      "Episode = 1069total_reward -500.840996637\n",
      "Episode = 1070total_reward -499.572837094\n",
      "Episode = 1071total_reward -264.584845009\n",
      "Episode = 1072total_reward -493.619809155\n",
      "Episode = 1073total_reward -251.183362458\n",
      "Episode = 1074total_reward -15.848111253\n",
      "Episode = 1075total_reward -498.274478598\n",
      "Episode = 1076total_reward -262.884217299\n",
      "Episode = 1077total_reward -485.797891036\n",
      "Episode = 1078total_reward -253.692169871\n",
      "Episode = 1079total_reward -271.035886917\n",
      "Episode = 1080total_reward -259.156137698\n",
      "Episode = 1081total_reward -263.18168202\n",
      "Episode = 1082total_reward -488.541034988\n",
      "Episode = 1083total_reward -280.881596906\n",
      "Episode = 1084total_reward -247.119090237\n",
      "Episode = 1085total_reward -505.580580949\n",
      "Episode = 1086total_reward -476.910899309\n",
      "Episode = 1087total_reward -265.740714001\n",
      "Episode = 1088total_reward -715.938111933\n",
      "Episode = 1089total_reward -245.604571118\n",
      "Episode = 1090total_reward -265.447542633\n",
      "Episode = 1091total_reward -678.144908123\n",
      "Episode = 1092total_reward -69.674112804\n",
      "Episode = 1093total_reward -491.061455481\n",
      "Episode = 1094total_reward -259.530795211\n",
      "Episode = 1095total_reward -255.084297439\n",
      "Episode = 1096total_reward -503.719981589\n",
      "Episode = 1097total_reward -783.014456369\n",
      "Episode = 1098total_reward -258.754048266\n",
      "Episode = 1099total_reward -255.113593767\n",
      "Episode = 1100total_reward -260.375744408\n",
      "Episode = 1101total_reward -253.872563163\n",
      "Episode = 1102total_reward -526.929669821\n",
      "Episode = 1103total_reward -648.202920847\n",
      "Episode = 1104total_reward -715.650608601\n",
      "Episode = 1105total_reward -501.776342807\n",
      "Episode = 1106total_reward -489.230048277\n",
      "Episode = 1107total_reward -259.857045692\n",
      "Episode = 1108total_reward -643.698314626\n",
      "Episode = 1109total_reward -267.766166873\n",
      "Episode = 1110total_reward -257.815643348\n",
      "Episode = 1111total_reward -748.962511364\n",
      "Episode = 1112total_reward -20.4246801943\n",
      "Episode = 1113total_reward -255.509974528\n",
      "Episode = 1114total_reward -529.456140347\n",
      "Episode = 1115total_reward -873.486297304\n",
      "Episode = 1116total_reward -484.580090287\n",
      "Episode = 1117total_reward -493.614244428\n",
      "Episode = 1118total_reward -479.452590714\n",
      "Episode = 1119total_reward -868.197832843\n",
      "Episode = 1120total_reward -481.089308057\n",
      "Episode = 1121total_reward -930.391281917\n",
      "Episode = 1122total_reward -501.898908937\n",
      "Episode = 1123total_reward -957.547352157\n",
      "Episode = 1124total_reward -501.443358079\n",
      "Episode = 1125total_reward -267.010934094\n",
      "Episode = 1126total_reward -477.399577549\n",
      "Episode = 1127total_reward -727.903110888\n",
      "Episode = 1128total_reward -488.434566033\n",
      "Episode = 1129total_reward -488.417805751\n",
      "Episode = 1130total_reward -21.363688238\n",
      "Episode = 1131total_reward -486.885510185\n",
      "Episode = 1132total_reward -259.731675475\n",
      "Episode = 1133total_reward -47.4547615641\n",
      "Episode = 1134total_reward -494.325505254\n",
      "Episode = 1135total_reward -582.721290641\n",
      "Episode = 1136total_reward -500.684393562\n",
      "Episode = 1137total_reward -736.17212037\n",
      "Episode = 1138total_reward -498.18101008\n",
      "Episode = 1139total_reward -22.696709083\n",
      "Episode = 1140total_reward -259.11646734\n",
      "Episode = 1141total_reward -737.060963163\n",
      "Episode = 1142total_reward -628.919211746\n",
      "Episode = 1143total_reward -487.742033661\n",
      "Episode = 1144total_reward -482.068254834\n",
      "Episode = 1145total_reward -244.197386862\n",
      "Episode = 1146total_reward -480.884349304\n",
      "Episode = 1147total_reward -242.12950435\n",
      "Episode = 1148total_reward -262.254091489\n",
      "Episode = 1149total_reward -496.887452211\n",
      "Episode = 1150total_reward -918.692474155\n",
      "Episode = 1151total_reward -743.583809833\n",
      "Episode = 1152total_reward -496.730372625\n",
      "Episode = 1153total_reward -262.803815289\n",
      "Episode = 1154total_reward -491.209892464\n",
      "Episode = 1155total_reward -656.250627212\n",
      "Episode = 1156total_reward -21.1252628571\n",
      "Episode = 1157total_reward -260.086493446\n",
      "Episode = 1158total_reward -763.998415634\n",
      "Episode = 1159total_reward -509.993733231\n",
      "Episode = 1160total_reward -491.517002473\n",
      "Episode = 1161total_reward -758.808260055\n",
      "Episode = 1162total_reward -507.280795586\n",
      "Episode = 1163total_reward -492.235177039\n",
      "Episode = 1164total_reward -923.197663938\n",
      "Episode = 1165total_reward -719.865441011\n",
      "Episode = 1166total_reward -739.629095223\n",
      "Episode = 1167total_reward -497.053226154\n",
      "Episode = 1168total_reward -687.385036791\n",
      "Episode = 1169total_reward -495.992671755\n",
      "Episode = 1170total_reward -258.147660873\n",
      "Episode = 1171total_reward -501.019766081\n",
      "Episode = 1172total_reward -503.41980488\n",
      "Episode = 1173total_reward -455.020348997\n",
      "Episode = 1174total_reward -502.67142786\n",
      "Episode = 1175total_reward -607.806499788\n",
      "Episode = 1176total_reward -509.286687139\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "Episode = 1177total_reward -248.025028659\n"
     ]
    }
   ],
   "source": [
    "## TODO: Train your agent here.\n",
    "import sys\n",
    "import pandas as pd\n",
    "from agents.agent import DDPG\n",
    "#from task import Task\n",
    "from gymtask import Task\n",
    "from replaybuffer import ReplayBuffer\n",
    "import numpy as np\n",
    "from actor import ActorNetwork\n",
    "import tensorflow as tf\n",
    "import csv\n",
    "\n",
    "\n",
    "train_length = 2000\n",
    "#Taking off \n",
    "\n",
    "#runtime = 5.                                     # time limit of the episode\n",
    "init_pose = np.array([0.0, 0.0, 0.1, 0.0, 0.0, 0.0])  # initial pose\n",
    "init_velocities = np.array([0.0, 0.0, 0.0])         # initial velocities\n",
    "init_angle_velocities = np.array([0.0, 0.0, 0.0])   # initial angle velocities\n",
    "#target_pose = np.array([0.0, 0.0, 10.0])  # target pose\n",
    "\n",
    "# Setup\n",
    "#task = Task(init_pose, init_velocities, init_angle_velocities, runtime)\n",
    "\n",
    "labels = ['time', 'x', 'y', 'z', 'phi', 'theta', 'psi', 'x_velocity',\n",
    "          'y_velocity', 'z_velocity', 'phi_velocity', 'theta_velocity',\n",
    "          'psi_velocity', 'rotor_speed1', 'rotor_speed2', 'rotor_speed3', 'rotor_speed4']\n",
    "results = {x : [] for x in labels}\n",
    "\n",
    "np.random.seed(1234)\n",
    "tf.set_random_seed(1234)\n",
    "    \n",
    "with tf.Session() as sess:\n",
    "    target_pos = np.array([0.0, 0.0, 10.0])\n",
    "    #print(\"1\")\n",
    "    #task = Task(init_pose = init_pose, target_pos=target_pos)\n",
    "    #print(\"2\")\n",
    "    \n",
    "    task = Task()\n",
    "    agent = DDPG(task,sess) \n",
    "    \n",
    "    #print(agent.env.sim.init_pose, agent.env.target_pos)\n",
    "\n",
    "    for i_episode in range(1, train_length+1):\n",
    "        #print(\"dd\")\n",
    "        state = agent.reset_episode() # start a new episode\n",
    "        #print(\"cc\")\n",
    "        total_value = 0\n",
    "        while True:\n",
    "            #print(\"123\")\n",
    "            action = agent.act(state) \n",
    "            #print(action)\n",
    "            next_state, reward, done = task.step(action)\n",
    "            total_value += reward\n",
    "            #print(\"abc\")\n",
    "            agent.step(state, action, reward, done, next_state)\n",
    "            state = next_state\n",
    "            total_value += reward\n",
    "            if done:\n",
    "                print(\"\\rEpisode = {:4d}\".format(i_episode), end=\"\")  # [debug]\n",
    "                print(\"total_reward\", total_value)\n",
    "                break\n",
    "        sys.stdout.flush()\n",
    "    \n",
    "    \n",
    "    file_output = 'data1.txt'                         # file name for saved results\n",
    "\n",
    "\n",
    "\n",
    "    done = False\n",
    "\n",
    "\n",
    "    # Run the simulation, and save the results.\n",
    "    with open(file_output, 'w') as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        writer.writerow(labels)\n",
    "        state = agent.reset_episode() # start a new episode\n",
    "\n",
    "        while True:\n",
    "            #print(\"abc\")\n",
    "            rotor_speeds = agent.act(state)\n",
    "            print(rotor_speeds)\n",
    "            s, reward, done = task.step(rotor_speeds)\n",
    "            #print(s, reward, done)\n",
    "            to_write = [task.sim.time] + list(task.sim.pose) + list(task.sim.v) + list(task.sim.angular_v) + list(rotor_speeds)\n",
    "            for ii in range(len(labels)):\n",
    "                results[labels[ii]].append(to_write[ii])\n",
    "\n",
    "            writer.writerow(to_write)\n",
    "            #print(s, reward, done)\n",
    "            #print(agent.task.sim.time)\n",
    "            if done:\n",
    "                break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Plot the Rewards\n",
    "\n",
    "Once you are satisfied with your performance, plot the episode rewards, either from a single run, or averaged over multiple runs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import csv\n",
    "import numpy as np\n",
    "from task import Task\n",
    "\n",
    "\n",
    "file_output = 'data1.txt'                         # file name for saved results\n",
    "\n",
    "\n",
    "\n",
    "done = False\n",
    "labels = ['time', 'x', 'y', 'z', 'phi', 'theta', 'psi', 'x_velocity',\n",
    "          'y_velocity', 'z_velocity', 'phi_velocity', 'theta_velocity',\n",
    "          'psi_velocity', 'rotor_speed1', 'rotor_speed2', 'rotor_speed3', 'rotor_speed4']\n",
    "results = {x : [] for x in labels}\n",
    "\n",
    "# Run the simulation, and save the results.\n",
    "with open(file_output, 'w') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerow(labels)\n",
    "    state = agent.reset_episode() # start a new episode\n",
    "\n",
    "    while True:\n",
    "        print(\"abc\")\n",
    "        rotor_speeds = agent.act(state)\n",
    "        s, reward, done = task.step(rotor_speeds)\n",
    "        print(s, reward, done)\n",
    "        to_write = [task.sim.time] + list(task.sim.pose) + list(task.sim.v) + list(task.sim.angular_v) + list(rotor_speeds)\n",
    "        for ii in range(len(labels)):\n",
    "            results[labels[ii]].append(to_write[ii])\n",
    "            \n",
    "        writer.writerow(to_write)\n",
    "        #print(s, reward, done)\n",
    "        #print(agent.task.sim.time)\n",
    "        if done:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO: Plot the rewards.\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.plot(results['time'], results['x'], label='x')\n",
    "plt.plot(results['time'], results['y'], label='y')\n",
    "plt.plot(results['time'], results['z'], label='z')\n",
    "plt.legend()\n",
    "_ = plt.ylim()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(results['time'], results['x_velocity'], label='x_hat')\n",
    "plt.plot(results['time'], results['y_velocity'], label='y_hat')\n",
    "plt.plot(results['time'], results['z_velocity'], label='z_hat')\n",
    "plt.legend()\n",
    "_ = plt.ylim()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(results['time'], results['rotor_speed1'], label='Rotor 1 revolutions / second')\n",
    "plt.plot(results['time'], results['rotor_speed2'], label='Rotor 2 revolutions / second')\n",
    "plt.plot(results['time'], results['rotor_speed3'], label='Rotor 3 revolutions / second')\n",
    "plt.plot(results['time'], results['rotor_speed4'], label='Rotor 4 revolutions / second')\n",
    "plt.legend()\n",
    "_ = plt.ylim()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Reflections\n",
    "\n",
    "**Question 1**: Describe the task that you specified in `task.py`.  How did you design the reward function?\n",
    "\n",
    "**Answer**: My task is to hover in the sky. The initial position is 0,0,10 and the target position is the same. The reward function is the default one that give agent negetive reward if the agent is away from the target pos.\n",
    "\n",
    "My quodcopter can hover, but it seems fly too high."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2**: Discuss your agent briefly, using the following questions as a guide:\n",
    "\n",
    "- What learning algorithm(s) did you try? What worked best for you?\n",
    "- What was your final choice of hyperparameters (such as $\\alpha$, $\\gamma$, $\\epsilon$, etc.)?\n",
    "- What neural network architecture did you use (if any)? Specify layers, sizes, activation functions, etc.\n",
    "\n",
    "**Answer**:\n",
    "The algorithm I chose is DDPG, or actor/critic. \n",
    "\n",
    "hyperparameters: tau= 0.0001, gamma = 0.99.\n",
    "\n",
    "I used default network architecture as I copied it from the course."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3**: Using the episode rewards plot, discuss how the agent learned over time.\n",
    "\n",
    "- Was it an easy task to learn or hard?\n",
    "- Was there a gradual learning curve, or an aha moment?\n",
    "- How good was the final performance of the agent? (e.g. mean rewards over the last 10 episodes)\n",
    "\n",
    "**Answer**: It's so hard and I need some a reviewer to give me some feedback as I am stuck in it for about 3 weeks.\n",
    "\n",
    "It's learning very slowly and I don't see any hope that it can succeed.\n",
    "\n",
    "The final performance is not good. It fly too high away."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4**: Briefly summarize your experience working on this project. You can use the following prompts for ideas.\n",
    "\n",
    "- What was the hardest part of the project? (e.g. getting started, plotting, specifying the task, etc.)\n",
    "- Did you find anything interesting in how the quadcopter or your agent behaved?\n",
    "\n",
    "**Answer**: Hardest part: I tried many ways to improve the architecture and reward function, but I don't know whether my agent is better or not. It's really frustrating.\n",
    "\n",
    "It seems that my agent can learn only one of the rator at any given time. It can't learn 4 rators together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Train an agent for MountainCarContinuous v0\n",
    "from gymtask import Task\n",
    "import sys\n",
    "import pandas as pd\n",
    "from agents.agent import DDPG\n",
    "\n",
    "from replaybuffer import ReplayBuffer\n",
    "import numpy as np\n",
    "\n",
    "pretrain_length = 1000\n",
    "\n",
    "task = Task()\n",
    "agent = DDPG(task)\n",
    "\n",
    "\n",
    "for i_episode in range(1, pretrain_length+1):\n",
    "    state = agent.reset_episode() # start a new episode\n",
    "    total_value = 0\n",
    "    while True:\n",
    "\n",
    "        action = agent.act(state) \n",
    "\n",
    "        next_state, reward, done = task.step(action)\n",
    "        total_value += reward\n",
    "        agent.step(action,reward, next_state, done)\n",
    "        state = next_state\n",
    "        if done:\n",
    "            print(\"\\rEpisode = {:4d}\".format(i_episode), end=\": \")  # [debug]\n",
    "            print(total_value)\n",
    "            break\n",
    "    sys.stdout.flush()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = agent.reset_episode()\n",
    "n = 0\n",
    "total_reward = 0\n",
    "while True:\n",
    "    n += 1\n",
    "    action = agent.act(state)\n",
    "    next_state, reward, done = task.step(action)\n",
    "    #agent.step(action, reward, next_state, done)\n",
    "    total_reward += reward\n",
    "    #print(n, state, action, reward, \"/n\")\n",
    "    #print(total_reward, \"/n\")\n",
    "    state = next_state\n",
    "    \n",
    "    if done:\n",
    "        print(\"done\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple, deque\n",
    "\n",
    "a = deque(maxlen = 10)\n",
    "a.append(1)\n",
    "print(len(a))\n",
    "a.append(2)\n",
    "print(len(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import gym\n",
    "from gym import wrappers\n",
    "import tflearn\n",
    "import argparse\n",
    "import pprint as pp\n",
    "from replay_buffer import ReplayBuffer\n",
    "from actor import ActorNetwork\n",
    "from critic import CriticNetwork\n",
    "from ounoise import OrnsteinUhlenbeckActionNoise\n",
    "from task import Task\n",
    "\n",
    "def build_summaries():\n",
    "    episode_reward = tf.Variable(0.)\n",
    "    tf.summary.scalar(\"Reward\", episode_reward)\n",
    "    episode_ave_max_q = tf.Variable(0.)\n",
    "    tf.summary.scalar(\"Qmax Value\", episode_ave_max_q)\n",
    "\n",
    "    summary_vars = [episode_reward, episode_ave_max_q]\n",
    "    summary_ops = tf.summary.merge_all()\n",
    "\n",
    "    return summary_ops, summary_vars\n",
    "\n",
    "# ===========================\n",
    "#   Agent Training\n",
    "# ===========================\n",
    "\n",
    "def train(sess, env, args, actor, critic, actor_noise):\n",
    "\n",
    "    # Set up summary Ops\n",
    "    summary_ops, summary_vars = build_summaries()\n",
    "\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    writer = tf.summary.FileWriter(args['summary_dir'], sess.graph)\n",
    "\n",
    "    # Initialize target network weights\n",
    "    actor.update_target_network()\n",
    "    critic.update_target_network()\n",
    "\n",
    "    # Initialize replay memory\n",
    "    replay_buffer = ReplayBuffer(int(args['buffer_size']), int(args['random_seed']))\n",
    "\n",
    "    # Needed to enable BatchNorm. \n",
    "    # This hurts the performance on Pendulum but could be useful\n",
    "    # in other environments.\n",
    "    # tflearn.is_training(True)\n",
    "\n",
    "    for i in range(int(args['max_episodes'])):\n",
    "\n",
    "        s = env.reset()\n",
    "\n",
    "        ep_reward = 0\n",
    "        ep_ave_max_q = 0\n",
    "\n",
    "        for j in range(int(args['max_episode_len'])):\n",
    "\n",
    "            if args['render_env']:\n",
    "                env.render()\n",
    "\n",
    "            # Added exploration noise\n",
    "            #a = actor.predict(np.reshape(s, (1, 3))) + (1. / (1. + i))\n",
    "            a = actor.predict(np.reshape(s, (1, actor.s_dim))) + actor_noise()\n",
    "\n",
    "            s2, r, terminal, info = env.step(a[0])\n",
    "\n",
    "            replay_buffer.add(np.reshape(s, (actor.s_dim,)), np.reshape(a, (actor.a_dim,)), r,\n",
    "                              terminal, np.reshape(s2, (actor.s_dim,)))\n",
    "\n",
    "            # Keep adding experience to the memory until\n",
    "            # there are at least minibatch size samples\n",
    "            if replay_buffer.size() > int(args['minibatch_size']):\n",
    "                s_batch, a_batch, r_batch, t_batch, s2_batch = \\\n",
    "                    replay_buffer.sample_batch(int(args['minibatch_size']))\n",
    "\n",
    "                # Calculate targets\n",
    "                target_q = critic.predict_target(\n",
    "                    s2_batch, actor.predict_target(s2_batch))\n",
    "\n",
    "                y_i = []\n",
    "                for k in range(int(args['minibatch_size'])):\n",
    "                    if t_batch[k]:\n",
    "                        y_i.append(r_batch[k])\n",
    "                    else:\n",
    "                        y_i.append(r_batch[k] + critic.gamma * target_q[k])\n",
    "\n",
    "                # Update the critic given the targets\n",
    "                predicted_q_value, _ = critic.train(\n",
    "                    s_batch, a_batch, np.reshape(y_i, (int(args['minibatch_size']), 1)))\n",
    "\n",
    "                ep_ave_max_q += np.amax(predicted_q_value)\n",
    "\n",
    "                # Update the actor policy using the sampled gradient\n",
    "                a_outs = actor.predict(s_batch)\n",
    "                grads = critic.action_gradients(s_batch, a_outs)\n",
    "                actor.train(s_batch, grads[0])\n",
    "\n",
    "                # Update target networks\n",
    "                actor.update_target_network()\n",
    "                critic.update_target_network()\n",
    "\n",
    "            s = s2\n",
    "            ep_reward += r\n",
    "\n",
    "            if terminal:\n",
    "\n",
    "                summary_str = sess.run(summary_ops, feed_dict={\n",
    "                    summary_vars[0]: ep_reward,\n",
    "                    summary_vars[1]: ep_ave_max_q / float(j)\n",
    "                })\n",
    "\n",
    "                writer.add_summary(summary_str, i)\n",
    "                writer.flush()\n",
    "\n",
    "                print('| Reward: {:d} | Episode: {:d} | Qmax: {:.4f}'.format(int(ep_reward), \\\n",
    "                        i, (ep_ave_max_q / float(j))))\n",
    "                break\n",
    "\n",
    "def main(args):\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "\n",
    "        #env = gym.make(args['env'])\n",
    "        #np.random.seed(int(args['random_seed']))\n",
    "        #tf.set_random_seed(int(args['random_seed']))\n",
    "        #env.seed(int(args['random_seed']))\n",
    "        env = Task()\n",
    "        \n",
    "        state_dim = env.observation_space.shape[0]\n",
    "        action_dim = env.action_space.shape[0]\n",
    "        action_bound = env.action_space.high\n",
    "        # Ensure action bound is symmetric\n",
    "        assert (env.action_space.high == -env.action_space.low)\n",
    "\n",
    "        actor = ActorNetwork(sess, state_dim, action_dim, action_bound,\n",
    "                             float(args['actor_lr']), float(args['tau']),\n",
    "                             int(args['minibatch_size']))\n",
    "\n",
    "        critic = CriticNetwork(sess, state_dim, action_dim,\n",
    "                               float(args['critic_lr']), float(args['tau']),\n",
    "                               float(args['gamma']),\n",
    "                               actor.get_num_trainable_vars())\n",
    "        \n",
    "        actor_noise = OrnsteinUhlenbeckActionNoise(mu=np.zeros(action_dim))\n",
    "\n",
    "        if args['use_gym_monitor']:\n",
    "            if not args['render_env']:\n",
    "                env = wrappers.Monitor(\n",
    "                    env, args['monitor_dir'], video_callable=False, force=True)\n",
    "            else:\n",
    "                env = wrappers.Monitor(env, args['monitor_dir'], force=True)\n",
    "\n",
    "        train(sess, env, args, actor, critic, actor_noise)\n",
    "\n",
    "        if args['use_gym_monitor']:\n",
    "            env.monitor.close()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    parser = argparse.ArgumentParser(description='provide arguments for DDPG agent')\n",
    "\n",
    "    # agent parameters\n",
    "    parser.add_argument('--actor-lr', help='actor network learning rate', default=0.0001)\n",
    "    parser.add_argument('--critic-lr', help='critic network learning rate', default=0.001)\n",
    "    parser.add_argument('--gamma', help='discount factor for critic updates', default=0.99)\n",
    "    parser.add_argument('--tau', help='soft target update parameter', default=0.001)\n",
    "    parser.add_argument('--buffer-size', help='max size of the replay buffer', default=1000000)\n",
    "    parser.add_argument('--minibatch-size', help='size of minibatch for minibatch-SGD', default=64)\n",
    "\n",
    "    # run parameters\n",
    "    parser.add_argument('--env', help='choose the gym env- tested on {Pendulum-v0}', default='Pendulum-v0')\n",
    "    parser.add_argument('--random-seed', help='random seed for repeatability', default=1234)\n",
    "    parser.add_argument('--max-episodes', help='max num of episodes to do while training', default=50000)\n",
    "    parser.add_argument('--max-episode-len', help='max length of 1 episode', default=1000)\n",
    "    parser.add_argument('--render-env', help='render the gym env', action='store_true')\n",
    "    parser.add_argument('--use-gym-monitor', help='record gym results', action='store_true')\n",
    "    parser.add_argument('--monitor-dir', help='directory for storing gym results', default='./results/gym_ddpg')\n",
    "    parser.add_argument('--summary-dir', help='directory for storing tensorboard info', default='./results/tf_ddpg')\n",
    "\n",
    "    parser.set_defaults(render_env=False)\n",
    "    parser.set_defaults(use_gym_monitor=True)\n",
    "    \n",
    "    args = vars(parser.parse_args())\n",
    "    \n",
    "    pp.pprint(args)\n",
    "\n",
    "    main(args)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
